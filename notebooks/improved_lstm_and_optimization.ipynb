{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314b367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a51d9",
   "metadata": {},
   "source": [
    "# Improved LSTM Model and Portfolio Optimization\n",
    "\n",
    "This notebook implements an enhanced LSTM model with better architecture and robust portfolio optimization using modern portfolio theory with ESG constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b588095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecf1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ecd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(\"data/processed/MultiIndex_stock_data.csv\", header=[0,1], index_col=0)\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "esg_scores = pd.read_csv(\"data/raw_data/esg_scores.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c970cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "Index(['AAPL', 'ABT', 'ADBE', 'AMGN', 'AMZN'], dtype='object')\n",
      "\n",
      "Column levels:\n",
      "[['AAPL', 'ABT', 'ADBE', 'AMGN', 'AMZN', 'BA', 'BKNG', 'BLK', 'BMY', 'CAT', 'COST', 'CRM', 'CSCO', 'CVX', 'DHR', 'DIS', 'FIS', 'GE', 'GILD', 'GOOGL', 'HON', 'IBM', 'INTC', 'JPM', 'KO', 'LIN', 'LMT', 'MCD', 'MDT', 'META', 'MMM', 'MRK', 'MSFT', 'NFLX', 'NKE', 'NVDA', 'ORCL', 'PEP', 'PFE', 'PYPL', 'QCOM', 'SAP', 'SBUX', 'SPGI', 'T', 'TSLA', 'TXN', 'UNH', 'V', 'WMT', 'ZTS'], ['20DayRet', '20DayVol', 'Adj Close', 'Close', 'DailyRet', 'High', 'Low', 'Open', 'Volume', 'Z20DayRet', 'Z20DayVol']]\n",
      "\n",
      "ESG Scores Info:\n",
      "  ticker  esg_score\n",
      "0   AAPL   0.587270\n",
      "1   MSFT   0.875357\n",
      "2  GOOGL   0.765997\n",
      "3   AMZN   0.699329\n",
      "4   TSLA   0.478009\n",
      "\n",
      "Sample data for first stock:\n",
      "            20DayRet  20DayVol  Adj Close      Close  DailyRet       High  \\\n",
      "Date                                                                        \n",
      "2015-08-03 -0.060000  0.016946  26.496563  29.610001 -0.023578  30.642500   \n",
      "2015-08-04 -0.087915  0.018152  25.646452  28.660000 -0.032084  29.424999   \n",
      "2015-08-05 -0.058497  0.017648  25.816473  28.850000  0.006629  29.360001   \n",
      "2015-08-06 -0.036803  0.017184  25.872654  28.782499  0.002176  29.125000   \n",
      "2015-08-07 -0.058705  0.015893  25.960295  28.879999  0.003387  29.062500   \n",
      "\n",
      "                  Low       Open     Volume  Z20DayRet  Z20DayVol  \n",
      "Date                                                               \n",
      "2015-08-03  29.379999  30.375000  279904000  -1.082105   0.114540  \n",
      "2015-08-04  28.312500  29.355000  496554400  -1.447145   0.286316  \n",
      "2015-08-05  28.025000  28.237499  397250400  -1.062455   0.214552  \n",
      "2015-08-06  28.530001  28.992500  211612000  -0.778759   0.148371  \n",
      "2015-08-07  28.625000  28.645000  154681600  -1.065168  -0.035441  \n"
     ]
    }
   ],
   "source": [
    "# Diagnostic prints\n",
    "print(\"DataFrame Info:\")\n",
    "print(merged_df.columns.levels[0][:5])  # Print first 5 stock tickers\n",
    "print(\"\\nColumn levels:\")\n",
    "print(merged_df.columns.levels)\n",
    "print(\"\\nESG Scores Info:\")\n",
    "print(esg_scores.head())\n",
    "print(\"\\nSample data for first stock:\")\n",
    "first_stock = merged_df.columns.levels[0][0]\n",
    "print(merged_df[first_stock].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28d1fe",
   "metadata": {},
   "source": [
    "## 1. Improved Data Preprocessing\n",
    "\n",
    "Implementing robust data preprocessing with better feature scaling and cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "042d5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(data, lookback=60, forecast_horizon=1):\n",
    "    \"\"\"\n",
    "    Prepare sequence data with proper padding and scaling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(data)\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - lookback - forecast_horizon + 1):\n",
    "            X.append(scaled_data[i:(i + lookback)])\n",
    "            y.append(scaled_data[i + lookback:i + lookback + forecast_horizon, 0])\n",
    "        \n",
    "        return np.array(X), np.array(y), scaler\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prepare_sequence_data: {str(e)}\")\n",
    "        print(f\"Data shape: {data.shape if hasattr(data, 'shape') else 'no shape'}\")\n",
    "        raise\n",
    "\n",
    "def create_time_series_cv(n_splits=5):\n",
    "    \"\"\"\n",
    "    Create time series cross-validation splits with appropriate test size\n",
    "    \"\"\"\n",
    "    # Calculate an appropriate test size that allows for n_splits\n",
    "    # For TimeSeriesSplit, we need: n_samples >= (n_splits + 1) * test_size\n",
    "    n_samples = len(merged_df)\n",
    "    max_test_size = n_samples // (n_splits + 1)\n",
    "    test_size = min(max_test_size, int(len(merged_df) * 0.2))\n",
    "    \n",
    "    return TimeSeriesSplit(n_splits=n_splits, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f59301",
   "metadata": {},
   "source": [
    "## 2. Enhanced LSTM Model Architecture\n",
    "\n",
    "Implementing a bidirectional LSTM with attention and batch normalization for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4667f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_lstm_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention layer\n",
    "    attention = layers.Dense(1, activation='tanh')(x)\n",
    "    attention = layers.Flatten()(attention)\n",
    "    attention_weights = layers.Activation('softmax')(attention)\n",
    "    attention_weights = layers.RepeatVector(64)(attention_weights)\n",
    "    attention_weights = layers.Permute([2, 1])(attention_weights)\n",
    "    \n",
    "    sent_representation = layers.multiply([x, attention_weights])\n",
    "    sent_representation = layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(sent_representation)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(32, activation='relu')(sent_representation)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a519797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_tensor_shape(tensor, name):\n",
    "    print(f\"{name} shape: {tensor.shape if hasattr(tensor, 'shape') else 'No shape'}\")\n",
    "    print(f\"{name} type: {type(tensor)}\")\n",
    "    if isinstance(tensor, np.ndarray) or tf.is_tensor(tensor):\n",
    "        print(f\"{name} dtype: {tensor.dtype}\")\n",
    "    if hasattr(tensor, 'isna'):\n",
    "        print(f\"{name} has NaN: {tensor.isna().any()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def test_model_batch(X_sample, y_sample, input_shape):\n",
    "    print(\"Testing model with small batch...\")\n",
    "    try:\n",
    "        model = create_improved_lstm_model(input_shape)\n",
    "        print(\"Model created successfully\")\n",
    "        \n",
    "        debug_tensor_shape(X_sample, \"X_sample\")\n",
    "        debug_tensor_shape(y_sample, \"y_sample\")\n",
    "        \n",
    "        test_pred = model.predict(X_sample[:2])\n",
    "        print(\"Forward pass successful\")\n",
    "        debug_tensor_shape(test_pred, \"test_pred\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error in test_model_batch: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25528da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AAPL...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 2.4876 - mae: 1.3116 - val_loss: 0.5827 - val_mae: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 2.4876 - mae: 1.3116 - val_loss: 0.5827 - val_mae: 0.7550 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 1.8684 - mae: 1.1493 - val_loss: 0.5273 - val_mae: 0.7167 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 1.8684 - mae: 1.1493 - val_loss: 0.5273 - val_mae: 0.7167 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 1.4783 - mae: 1.0165 - val_loss: 0.5322 - val_mae: 0.7184 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 1.4783 - mae: 1.0165 - val_loss: 0.5322 - val_mae: 0.7184 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.3562 - mae: 0.9852 - val_loss: 0.4125 - val_mae: 0.6261 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 1.3562 - mae: 0.9852 - val_loss: 0.4125 - val_mae: 0.6261 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1312 - mae: 0.8986 - val_loss: 0.4330 - val_mae: 0.6397 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 1.1312 - mae: 0.8986 - val_loss: 0.4330 - val_mae: 0.6397 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.9855 - mae: 0.8166 - val_loss: 0.3529 - val_mae: 0.5676 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.9855 - mae: 0.8166 - val_loss: 0.3529 - val_mae: 0.5676 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.9809 - mae: 0.8226 - val_loss: 0.3321 - val_mae: 0.5466 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.9809 - mae: 0.8226 - val_loss: 0.3321 - val_mae: 0.5466 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.8774 - mae: 0.7595 - val_loss: 0.3290 - val_mae: 0.5439 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.8774 - mae: 0.7595 - val_loss: 0.3290 - val_mae: 0.5439 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.7103 - mae: 0.6779 - val_loss: 0.2616 - val_mae: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.7103 - mae: 0.6779 - val_loss: 0.2616 - val_mae: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.6768 - mae: 0.6461 - val_loss: 0.2745 - val_mae: 0.4898 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.6768 - mae: 0.6461 - val_loss: 0.2745 - val_mae: 0.4898 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.6294 - mae: 0.6305 - val_loss: 0.2097 - val_mae: 0.4089 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.6294 - mae: 0.6305 - val_loss: 0.2097 - val_mae: 0.4089 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5652 - mae: 0.6065 - val_loss: 0.1719 - val_mae: 0.3618 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5652 - mae: 0.6065 - val_loss: 0.1719 - val_mae: 0.3618 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.5632 - mae: 0.6009 - val_loss: 0.1676 - val_mae: 0.3616 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.5632 - mae: 0.6009 - val_loss: 0.1676 - val_mae: 0.3616 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.5448 - mae: 0.5754 - val_loss: 0.1092 - val_mae: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.5448 - mae: 0.5754 - val_loss: 0.1092 - val_mae: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.4909 - mae: 0.5334 - val_loss: 0.0900 - val_mae: 0.2385 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.4909 - mae: 0.5334 - val_loss: 0.0900 - val_mae: 0.2385 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.5028 - mae: 0.5471 - val_loss: 0.0803 - val_mae: 0.2232 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.5028 - mae: 0.5471 - val_loss: 0.0803 - val_mae: 0.2232 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.4007 - mae: 0.4991 - val_loss: 0.0720 - val_mae: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.4007 - mae: 0.4991 - val_loss: 0.0720 - val_mae: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.4049 - mae: 0.4719 - val_loss: 0.0520 - val_mae: 0.1727 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.4049 - mae: 0.4719 - val_loss: 0.0520 - val_mae: 0.1727 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3999 - mae: 0.4773 - val_loss: 0.0463 - val_mae: 0.1645 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3999 - mae: 0.4773 - val_loss: 0.0463 - val_mae: 0.1645 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.4226 - mae: 0.5009 - val_loss: 0.0503 - val_mae: 0.1787 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.4226 - mae: 0.5009 - val_loss: 0.0503 - val_mae: 0.1787 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.3577 - mae: 0.4638 - val_loss: 0.0497 - val_mae: 0.1783 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.3577 - mae: 0.4638 - val_loss: 0.0497 - val_mae: 0.1783 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.3020 - mae: 0.4375 - val_loss: 0.0407 - val_mae: 0.1551 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.3020 - mae: 0.4375 - val_loss: 0.0407 - val_mae: 0.1551 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2977 - mae: 0.4278 - val_loss: 0.0567 - val_mae: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2977 - mae: 0.4278 - val_loss: 0.0567 - val_mae: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.3292 - mae: 0.4397 - val_loss: 0.0557 - val_mae: 0.1956 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.3292 - mae: 0.4397 - val_loss: 0.0557 - val_mae: 0.1956 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.3211 - mae: 0.4309 - val_loss: 0.0478 - val_mae: 0.1758 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.3211 - mae: 0.4309 - val_loss: 0.0478 - val_mae: 0.1758 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.2757 - mae: 0.3934 - val_loss: 0.0450 - val_mae: 0.1612 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.2757 - mae: 0.3934 - val_loss: 0.0450 - val_mae: 0.1612 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.3168 - mae: 0.4411 - val_loss: 0.0867 - val_mae: 0.2415 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.3168 - mae: 0.4411 - val_loss: 0.0867 - val_mae: 0.2415 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.2465 - mae: 0.3828 - val_loss: 0.1042 - val_mae: 0.2723 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.2465 - mae: 0.3828 - val_loss: 0.1042 - val_mae: 0.2723 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.3133 - mae: 0.4325 - val_loss: 0.0621 - val_mae: 0.2110 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.3133 - mae: 0.4325 - val_loss: 0.0621 - val_mae: 0.2110 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2932 - mae: 0.4072 - val_loss: 0.0594 - val_mae: 0.2049 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2932 - mae: 0.4072 - val_loss: 0.0594 - val_mae: 0.2049 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.2961 - mae: 0.4200 - val_loss: 0.0653 - val_mae: 0.2147 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.2961 - mae: 0.4200 - val_loss: 0.0653 - val_mae: 0.2147 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2303 - mae: 0.3856 - val_loss: 0.0614 - val_mae: 0.2078 - learning_rate: 5.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.2303 - mae: 0.3856 - val_loss: 0.0614 - val_mae: 0.2078 - learning_rate: 5.0000e-04\n",
      "Fold 1 MSE: 0.040715\n",
      "Fold 1 MSE: 0.040715\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 1.7816 - mae: 1.0903 - val_loss: 0.3439 - val_mae: 0.5606 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 1.7816 - mae: 1.0903 - val_loss: 0.3439 - val_mae: 0.5606 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.1497 - mae: 0.8593 - val_loss: 0.0952 - val_mae: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.1497 - mae: 0.8593 - val_loss: 0.0952 - val_mae: 0.2722 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.9421 - mae: 0.7915 - val_loss: 0.0308 - val_mae: 0.1436 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.9421 - mae: 0.7915 - val_loss: 0.0308 - val_mae: 0.1436 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.7785 - mae: 0.6986 - val_loss: 0.0735 - val_mae: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.7785 - mae: 0.6986 - val_loss: 0.0735 - val_mae: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.5930 - mae: 0.5974 - val_loss: 0.1460 - val_mae: 0.3337 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.5930 - mae: 0.5974 - val_loss: 0.1460 - val_mae: 0.3337 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.5133 - mae: 0.5602 - val_loss: 0.1638 - val_mae: 0.3529 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.5133 - mae: 0.5602 - val_loss: 0.1638 - val_mae: 0.3529 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4784 - mae: 0.5299 - val_loss: 0.1459 - val_mae: 0.3285 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4784 - mae: 0.5299 - val_loss: 0.1459 - val_mae: 0.3285 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.4228 - mae: 0.5138 - val_loss: 0.1576 - val_mae: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.4228 - mae: 0.5138 - val_loss: 0.1576 - val_mae: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4087 - mae: 0.4955 - val_loss: 0.1762 - val_mae: 0.3484 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4087 - mae: 0.4955 - val_loss: 0.1762 - val_mae: 0.3484 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.3506 - mae: 0.4573 - val_loss: 0.1371 - val_mae: 0.2991 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.3506 - mae: 0.4573 - val_loss: 0.1371 - val_mae: 0.2991 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.3179 - mae: 0.4400 - val_loss: 0.1735 - val_mae: 0.3594 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.3179 - mae: 0.4400 - val_loss: 0.1735 - val_mae: 0.3594 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3473 - mae: 0.4498 - val_loss: 0.1267 - val_mae: 0.2735 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3473 - mae: 0.4498 - val_loss: 0.1267 - val_mae: 0.2735 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3372 - mae: 0.4450 - val_loss: 0.1227 - val_mae: 0.2746 - learning_rate: 5.0000e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3372 - mae: 0.4450 - val_loss: 0.1227 - val_mae: 0.2746 - learning_rate: 5.0000e-04\n",
      "Fold 2 MSE: 0.030822\n",
      "Fold 2 MSE: 0.030822\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 1.2930 - mae: 0.9245 - val_loss: 0.3789 - val_mae: 0.5351 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - loss: 1.2930 - mae: 0.9245 - val_loss: 0.3789 - val_mae: 0.5351 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.6793 - mae: 0.6602 - val_loss: 0.4989 - val_mae: 0.6312 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.6793 - mae: 0.6602 - val_loss: 0.4989 - val_mae: 0.6312 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4712 - mae: 0.5463 - val_loss: 0.6486 - val_mae: 0.7322 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4712 - mae: 0.5463 - val_loss: 0.6486 - val_mae: 0.7322 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3876 - mae: 0.4739 - val_loss: 0.7124 - val_mae: 0.7731 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3876 - mae: 0.4739 - val_loss: 0.7124 - val_mae: 0.7731 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.3478 - mae: 0.4443 - val_loss: 0.8562 - val_mae: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.3478 - mae: 0.4443 - val_loss: 0.8562 - val_mae: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3174 - mae: 0.4209 - val_loss: 0.9059 - val_mae: 0.8793 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3174 - mae: 0.4209 - val_loss: 0.9059 - val_mae: 0.8793 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2403 - mae: 0.3705 - val_loss: 1.0351 - val_mae: 0.9541 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2403 - mae: 0.3705 - val_loss: 1.0351 - val_mae: 0.9541 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.2424 - mae: 0.3739 - val_loss: 0.9727 - val_mae: 0.9191 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.2424 - mae: 0.3739 - val_loss: 0.9727 - val_mae: 0.9191 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2313 - mae: 0.3608 - val_loss: 1.0615 - val_mae: 0.9674 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2313 - mae: 0.3608 - val_loss: 1.0615 - val_mae: 0.9674 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2370 - mae: 0.3620 - val_loss: 1.1329 - val_mae: 0.9563 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2370 - mae: 0.3620 - val_loss: 1.1329 - val_mae: 0.9563 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2028 - mae: 0.3354 - val_loss: 1.0670 - val_mae: 0.9372 - learning_rate: 5.0000e-04\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.2028 - mae: 0.3354 - val_loss: 1.0670 - val_mae: 0.9372 - learning_rate: 5.0000e-04\n",
      "Fold 3 MSE: 0.378936\n",
      "Fold 3 MSE: 0.378936\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - loss: 0.7574 - mae: 0.6803 - val_loss: 1.0083 - val_mae: 0.9843 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - loss: 0.7574 - mae: 0.6803 - val_loss: 1.0083 - val_mae: 0.9843 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.4221 - mae: 0.5079 - val_loss: 1.0457 - val_mae: 1.0091 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.4221 - mae: 0.5079 - val_loss: 1.0457 - val_mae: 1.0091 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3101 - mae: 0.4298 - val_loss: 0.9897 - val_mae: 0.9821 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3101 - mae: 0.4298 - val_loss: 0.9897 - val_mae: 0.9821 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2734 - mae: 0.4051 - val_loss: 0.7504 - val_mae: 0.8491 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2734 - mae: 0.4051 - val_loss: 0.7504 - val_mae: 0.8491 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2343 - mae: 0.3733 - val_loss: 0.5200 - val_mae: 0.6965 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2343 - mae: 0.3733 - val_loss: 0.5200 - val_mae: 0.6965 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1794 - mae: 0.3235 - val_loss: 0.2869 - val_mae: 0.5078 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1794 - mae: 0.3235 - val_loss: 0.2869 - val_mae: 0.5078 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.1562 - mae: 0.2995 - val_loss: 0.1588 - val_mae: 0.3634 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.1562 - mae: 0.2995 - val_loss: 0.1588 - val_mae: 0.3634 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1368 - mae: 0.2859 - val_loss: 0.1295 - val_mae: 0.3320 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1368 - mae: 0.2859 - val_loss: 0.1295 - val_mae: 0.3320 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1338 - mae: 0.2779 - val_loss: 0.1093 - val_mae: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1338 - mae: 0.2779 - val_loss: 0.1093 - val_mae: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1070 - mae: 0.2475 - val_loss: 0.0801 - val_mae: 0.2456 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1070 - mae: 0.2475 - val_loss: 0.0801 - val_mae: 0.2456 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0937 - mae: 0.2345 - val_loss: 0.0953 - val_mae: 0.2742 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0937 - mae: 0.2345 - val_loss: 0.0953 - val_mae: 0.2742 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0894 - mae: 0.2316 - val_loss: 0.0649 - val_mae: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0894 - mae: 0.2316 - val_loss: 0.0649 - val_mae: 0.2245 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0707 - mae: 0.2059 - val_loss: 0.0586 - val_mae: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0707 - mae: 0.2059 - val_loss: 0.0586 - val_mae: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0622 - mae: 0.1948 - val_loss: 0.0730 - val_mae: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0622 - mae: 0.1948 - val_loss: 0.0730 - val_mae: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0639 - mae: 0.1960 - val_loss: 0.0664 - val_mae: 0.2301 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0639 - mae: 0.1960 - val_loss: 0.0664 - val_mae: 0.2301 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0550 - mae: 0.1830 - val_loss: 0.0525 - val_mae: 0.2031 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0550 - mae: 0.1830 - val_loss: 0.0525 - val_mae: 0.2031 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0495 - mae: 0.1740 - val_loss: 0.0817 - val_mae: 0.2585 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0495 - mae: 0.1740 - val_loss: 0.0817 - val_mae: 0.2585 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0439 - mae: 0.1645 - val_loss: 0.0905 - val_mae: 0.2751 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0439 - mae: 0.1645 - val_loss: 0.0905 - val_mae: 0.2751 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0436 - mae: 0.1617 - val_loss: 0.0655 - val_mae: 0.2284 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0436 - mae: 0.1617 - val_loss: 0.0655 - val_mae: 0.2284 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0408 - mae: 0.1595 - val_loss: 0.0866 - val_mae: 0.2655 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0408 - mae: 0.1595 - val_loss: 0.0866 - val_mae: 0.2655 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0380 - mae: 0.1524 - val_loss: 0.0758 - val_mae: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0380 - mae: 0.1524 - val_loss: 0.0758 - val_mae: 0.2433 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0343 - mae: 0.1463 - val_loss: 0.0774 - val_mae: 0.2486 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0343 - mae: 0.1463 - val_loss: 0.0774 - val_mae: 0.2486 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0319 - mae: 0.1396 - val_loss: 0.0754 - val_mae: 0.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0319 - mae: 0.1396 - val_loss: 0.0754 - val_mae: 0.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0341 - mae: 0.1452 - val_loss: 0.0824 - val_mae: 0.2616 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0341 - mae: 0.1452 - val_loss: 0.0824 - val_mae: 0.2616 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0337 - mae: 0.1449 - val_loss: 0.0767 - val_mae: 0.2523 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0337 - mae: 0.1449 - val_loss: 0.0767 - val_mae: 0.2523 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0306 - mae: 0.1374 - val_loss: 0.0749 - val_mae: 0.2469 - learning_rate: 5.0000e-04\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0306 - mae: 0.1374 - val_loss: 0.0749 - val_mae: 0.2469 - learning_rate: 5.0000e-04\n",
      "Fold 4 MSE: 0.052476\n",
      "Fold 4 MSE: 0.052476\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - loss: 0.8263 - mae: 0.7002 - val_loss: 1.9467 - val_mae: 1.3455 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - loss: 0.8263 - mae: 0.7002 - val_loss: 1.9467 - val_mae: 1.3455 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.5521 - mae: 0.5787 - val_loss: 1.9210 - val_mae: 1.3542 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.5521 - mae: 0.5787 - val_loss: 1.9210 - val_mae: 1.3542 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.4159 - mae: 0.5044 - val_loss: 1.6240 - val_mae: 1.2392 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.4159 - mae: 0.5044 - val_loss: 1.6240 - val_mae: 1.2392 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.3550 - mae: 0.4630 - val_loss: 0.8215 - val_mae: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.3550 - mae: 0.4630 - val_loss: 0.8215 - val_mae: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.2947 - mae: 0.4270 - val_loss: 0.6165 - val_mae: 0.7294 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.2947 - mae: 0.4270 - val_loss: 0.6165 - val_mae: 0.7294 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.2492 - mae: 0.3858 - val_loss: 1.0133 - val_mae: 0.9509 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.2492 - mae: 0.3858 - val_loss: 1.0133 - val_mae: 0.9509 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2017 - mae: 0.3551 - val_loss: 0.5094 - val_mae: 0.6421 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2017 - mae: 0.3551 - val_loss: 0.5094 - val_mae: 0.6421 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1708 - mae: 0.3241 - val_loss: 0.2271 - val_mae: 0.3810 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1708 - mae: 0.3241 - val_loss: 0.2271 - val_mae: 0.3810 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1517 - mae: 0.3018 - val_loss: 0.2121 - val_mae: 0.3667 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1517 - mae: 0.3018 - val_loss: 0.2121 - val_mae: 0.3667 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1315 - mae: 0.2845 - val_loss: 0.2333 - val_mae: 0.4006 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1315 - mae: 0.2845 - val_loss: 0.2333 - val_mae: 0.4006 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1112 - mae: 0.2591 - val_loss: 0.2186 - val_mae: 0.3919 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1112 - mae: 0.2591 - val_loss: 0.2186 - val_mae: 0.3919 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1030 - mae: 0.2500 - val_loss: 0.1989 - val_mae: 0.3718 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1030 - mae: 0.2500 - val_loss: 0.1989 - val_mae: 0.3718 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0920 - mae: 0.2403 - val_loss: 0.1945 - val_mae: 0.3690 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0920 - mae: 0.2403 - val_loss: 0.1945 - val_mae: 0.3690 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0796 - mae: 0.2207 - val_loss: 0.2058 - val_mae: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0796 - mae: 0.2207 - val_loss: 0.2058 - val_mae: 0.3731 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0682 - mae: 0.2056 - val_loss: 0.2342 - val_mae: 0.4145 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0682 - mae: 0.2056 - val_loss: 0.2342 - val_mae: 0.4145 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0677 - mae: 0.2052 - val_loss: 0.2307 - val_mae: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0677 - mae: 0.2052 - val_loss: 0.2307 - val_mae: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0603 - mae: 0.1952 - val_loss: 0.2307 - val_mae: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0603 - mae: 0.1952 - val_loss: 0.2307 - val_mae: 0.4031 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0561 - mae: 0.1892 - val_loss: 0.2338 - val_mae: 0.3981 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0561 - mae: 0.1892 - val_loss: 0.2338 - val_mae: 0.3981 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0497 - mae: 0.1772 - val_loss: 0.1994 - val_mae: 0.3568 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0497 - mae: 0.1772 - val_loss: 0.1994 - val_mae: 0.3568 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0486 - mae: 0.1766 - val_loss: 0.1865 - val_mae: 0.3445 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0486 - mae: 0.1766 - val_loss: 0.1865 - val_mae: 0.3445 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0485 - mae: 0.1777 - val_loss: 0.2090 - val_mae: 0.3775 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0485 - mae: 0.1777 - val_loss: 0.2090 - val_mae: 0.3775 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0458 - mae: 0.1697 - val_loss: 0.2069 - val_mae: 0.3720 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0458 - mae: 0.1697 - val_loss: 0.2069 - val_mae: 0.3720 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0446 - mae: 0.1684 - val_loss: 0.2065 - val_mae: 0.3730 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0446 - mae: 0.1684 - val_loss: 0.2065 - val_mae: 0.3730 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0461 - mae: 0.1714 - val_loss: 0.1792 - val_mae: 0.3327 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0461 - mae: 0.1714 - val_loss: 0.1792 - val_mae: 0.3327 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0454 - mae: 0.1702 - val_loss: 0.1962 - val_mae: 0.3577 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0454 - mae: 0.1702 - val_loss: 0.1962 - val_mae: 0.3577 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0418 - mae: 0.1641 - val_loss: 0.1883 - val_mae: 0.3517 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0418 - mae: 0.1641 - val_loss: 0.1883 - val_mae: 0.3517 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0438 - mae: 0.1677 - val_loss: 0.1817 - val_mae: 0.3389 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0438 - mae: 0.1677 - val_loss: 0.1817 - val_mae: 0.3389 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0409 - mae: 0.1625 - val_loss: 0.1858 - val_mae: 0.3419 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0409 - mae: 0.1625 - val_loss: 0.1858 - val_mae: 0.3419 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0399 - mae: 0.1611 - val_loss: 0.2127 - val_mae: 0.3833 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0399 - mae: 0.1611 - val_loss: 0.2127 - val_mae: 0.3833 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0391 - mae: 0.1586 - val_loss: 0.1959 - val_mae: 0.3601 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0391 - mae: 0.1586 - val_loss: 0.1959 - val_mae: 0.3601 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0386 - mae: 0.1575 - val_loss: 0.2086 - val_mae: 0.3775 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0386 - mae: 0.1575 - val_loss: 0.2086 - val_mae: 0.3775 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0396 - mae: 0.1602 - val_loss: 0.2056 - val_mae: 0.3740 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0396 - mae: 0.1602 - val_loss: 0.2056 - val_mae: 0.3740 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0393 - mae: 0.1588 - val_loss: 0.1862 - val_mae: 0.3477 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0393 - mae: 0.1588 - val_loss: 0.1862 - val_mae: 0.3477 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0382 - mae: 0.1585 - val_loss: 0.2024 - val_mae: 0.3693 - learning_rate: 2.5000e-04\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0382 - mae: 0.1585 - val_loss: 0.2024 - val_mae: 0.3693 - learning_rate: 2.5000e-04\n",
      "Fold 5 MSE: 0.179213\n",
      "Fold 5 MSE: 0.179213\n",
      "Error processing AAPL: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing ABT...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Error processing AAPL: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing ABT...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 482ms/step - loss: 2.9040 - mae: 1.4206 - val_loss: 0.9816 - val_mae: 0.9614 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 482ms/step - loss: 2.9040 - mae: 1.4206 - val_loss: 0.9816 - val_mae: 0.9614 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 2.3483 - mae: 1.3506 - val_loss: 0.8383 - val_mae: 0.8825 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 2.3483 - mae: 1.3506 - val_loss: 0.8383 - val_mae: 0.8825 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 2.2747 - mae: 1.3381 - val_loss: 0.6952 - val_mae: 0.7948 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - loss: 2.2747 - mae: 1.3381 - val_loss: 0.6952 - val_mae: 0.7948 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 1.9704 - mae: 1.2331 - val_loss: 0.5892 - val_mae: 0.7190 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 186ms/step - loss: 1.9704 - mae: 1.2331 - val_loss: 0.5892 - val_mae: 0.7190 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 1.6275 - mae: 1.1172 - val_loss: 0.5016 - val_mae: 0.6473 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 1.6275 - mae: 1.1172 - val_loss: 0.5016 - val_mae: 0.6473 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 1.5279 - mae: 1.0603 - val_loss: 0.3819 - val_mae: 0.5421 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - loss: 1.5279 - mae: 1.0603 - val_loss: 0.3819 - val_mae: 0.5421 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 1.5637 - mae: 1.0829 - val_loss: 0.3056 - val_mae: 0.4569 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 1.5637 - mae: 1.0829 - val_loss: 0.3056 - val_mae: 0.4569 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 1.1675 - mae: 0.9258 - val_loss: 0.2193 - val_mae: 0.3709 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - loss: 1.1675 - mae: 0.9258 - val_loss: 0.2193 - val_mae: 0.3709 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.0667 - mae: 0.8601 - val_loss: 0.1701 - val_mae: 0.3291 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - loss: 1.0667 - mae: 0.8601 - val_loss: 0.1701 - val_mae: 0.3291 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 1.1563 - mae: 0.9021 - val_loss: 0.1157 - val_mae: 0.2853 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 184ms/step - loss: 1.1563 - mae: 0.9021 - val_loss: 0.1157 - val_mae: 0.2853 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.9792 - mae: 0.8071 - val_loss: 0.0731 - val_mae: 0.2416 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 180ms/step - loss: 0.9792 - mae: 0.8071 - val_loss: 0.0731 - val_mae: 0.2416 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.8394 - mae: 0.7610 - val_loss: 0.0771 - val_mae: 0.2448 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - loss: 0.8394 - mae: 0.7610 - val_loss: 0.0771 - val_mae: 0.2448 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.8755 - mae: 0.7331 - val_loss: 0.0796 - val_mae: 0.2297 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.8755 - mae: 0.7331 - val_loss: 0.0796 - val_mae: 0.2297 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.8491 - mae: 0.7348 - val_loss: 0.1315 - val_mae: 0.3052 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - loss: 0.8491 - mae: 0.7348 - val_loss: 0.1315 - val_mae: 0.3052 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.6524 - mae: 0.6364 - val_loss: 0.1330 - val_mae: 0.3096 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - loss: 0.6524 - mae: 0.6364 - val_loss: 0.1330 - val_mae: 0.3096 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.5904 - mae: 0.5799 - val_loss: 0.1695 - val_mae: 0.3545 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 185ms/step - loss: 0.5904 - mae: 0.5799 - val_loss: 0.1695 - val_mae: 0.3545 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.6917 - mae: 0.6542 - val_loss: 0.2182 - val_mae: 0.4042 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - loss: 0.6917 - mae: 0.6542 - val_loss: 0.2182 - val_mae: 0.4042 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.5480 - mae: 0.5859 - val_loss: 0.2492 - val_mae: 0.4272 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 0.5480 - mae: 0.5859 - val_loss: 0.2492 - val_mae: 0.4272 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.5281 - mae: 0.5568 - val_loss: 0.2906 - val_mae: 0.4628 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - loss: 0.5281 - mae: 0.5568 - val_loss: 0.2906 - val_mae: 0.4628 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.4906 - mae: 0.5417 - val_loss: 0.3442 - val_mae: 0.5109 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - loss: 0.4906 - mae: 0.5417 - val_loss: 0.3442 - val_mae: 0.5109 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.5514 - mae: 0.5796 - val_loss: 0.3615 - val_mae: 0.5385 - learning_rate: 5.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 175ms/step - loss: 0.5514 - mae: 0.5796 - val_loss: 0.3615 - val_mae: 0.5385 - learning_rate: 5.0000e-04\n",
      "Fold 1 MSE: 0.073122\n",
      "Fold 1 MSE: 0.073122\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 263ms/step - loss: 2.2208 - mae: 1.2501 - val_loss: 0.0634 - val_mae: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 263ms/step - loss: 2.2208 - mae: 1.2501 - val_loss: 0.0634 - val_mae: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.6214 - mae: 1.0653 - val_loss: 0.0670 - val_mae: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - loss: 1.6214 - mae: 1.0653 - val_loss: 0.0670 - val_mae: 0.2159 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 1.2021 - mae: 0.9155 - val_loss: 0.0948 - val_mae: 0.2584 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 1.2021 - mae: 0.9155 - val_loss: 0.0948 - val_mae: 0.2584 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.9374 - mae: 0.7986 - val_loss: 0.1062 - val_mae: 0.2763 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 0.9374 - mae: 0.7986 - val_loss: 0.1062 - val_mae: 0.2763 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.7962 - mae: 0.7220 - val_loss: 0.0967 - val_mae: 0.2735 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.7962 - mae: 0.7220 - val_loss: 0.0967 - val_mae: 0.2735 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.6779 - mae: 0.6475 - val_loss: 0.1030 - val_mae: 0.2832 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.6779 - mae: 0.6475 - val_loss: 0.1030 - val_mae: 0.2832 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6260 - mae: 0.6268 - val_loss: 0.1337 - val_mae: 0.3210 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6260 - mae: 0.6268 - val_loss: 0.1337 - val_mae: 0.3210 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.5492 - mae: 0.5838 - val_loss: 0.1582 - val_mae: 0.3515 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.5492 - mae: 0.5838 - val_loss: 0.1582 - val_mae: 0.3515 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.5453 - mae: 0.5747 - val_loss: 0.1728 - val_mae: 0.3695 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.5453 - mae: 0.5747 - val_loss: 0.1728 - val_mae: 0.3695 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4846 - mae: 0.5375 - val_loss: 0.1647 - val_mae: 0.3566 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4846 - mae: 0.5375 - val_loss: 0.1647 - val_mae: 0.3566 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4622 - mae: 0.5308 - val_loss: 0.1616 - val_mae: 0.3526 - learning_rate: 5.0000e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4622 - mae: 0.5308 - val_loss: 0.1616 - val_mae: 0.3526 - learning_rate: 5.0000e-04\n",
      "Fold 2 MSE: 0.063361\n",
      "Fold 2 MSE: 0.063361\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 1.3624 - mae: 0.9370 - val_loss: 1.0645 - val_mae: 0.9907 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 1.3624 - mae: 0.9370 - val_loss: 1.0645 - val_mae: 0.9907 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.7423 - mae: 0.6820 - val_loss: 1.5550 - val_mae: 1.2047 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.7423 - mae: 0.6820 - val_loss: 1.5550 - val_mae: 1.2047 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5607 - mae: 0.5797 - val_loss: 1.5112 - val_mae: 1.1886 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5607 - mae: 0.5797 - val_loss: 1.5112 - val_mae: 1.1886 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.4644 - mae: 0.5316 - val_loss: 1.4233 - val_mae: 1.1430 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.4644 - mae: 0.5316 - val_loss: 1.4233 - val_mae: 1.1430 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4402 - mae: 0.5212 - val_loss: 1.2593 - val_mae: 1.0766 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4402 - mae: 0.5212 - val_loss: 1.2593 - val_mae: 1.0766 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3750 - mae: 0.4763 - val_loss: 1.2132 - val_mae: 1.0741 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3750 - mae: 0.4763 - val_loss: 1.2132 - val_mae: 1.0741 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3251 - mae: 0.4466 - val_loss: 1.2218 - val_mae: 1.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3251 - mae: 0.4466 - val_loss: 1.2218 - val_mae: 1.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.3254 - mae: 0.4406 - val_loss: 1.0517 - val_mae: 0.9859 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.3254 - mae: 0.4406 - val_loss: 1.0517 - val_mae: 0.9859 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2816 - mae: 0.4088 - val_loss: 0.9393 - val_mae: 0.9209 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2816 - mae: 0.4088 - val_loss: 0.9393 - val_mae: 0.9209 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.2955 - mae: 0.4269 - val_loss: 0.7153 - val_mae: 0.8090 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.2955 - mae: 0.4269 - val_loss: 0.7153 - val_mae: 0.8090 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.2539 - mae: 0.3900 - val_loss: 0.7038 - val_mae: 0.7884 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.2539 - mae: 0.3900 - val_loss: 0.7038 - val_mae: 0.7884 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2414 - mae: 0.3851 - val_loss: 0.8391 - val_mae: 0.8567 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2414 - mae: 0.3851 - val_loss: 0.8391 - val_mae: 0.8567 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2258 - mae: 0.3696 - val_loss: 0.7598 - val_mae: 0.8022 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2258 - mae: 0.3696 - val_loss: 0.7598 - val_mae: 0.8022 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2290 - mae: 0.3693 - val_loss: 0.5700 - val_mae: 0.6816 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2290 - mae: 0.3693 - val_loss: 0.5700 - val_mae: 0.6816 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2094 - mae: 0.3528 - val_loss: 0.6527 - val_mae: 0.7053 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2094 - mae: 0.3528 - val_loss: 0.6527 - val_mae: 0.7053 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.2093 - mae: 0.3573 - val_loss: 0.5340 - val_mae: 0.6562 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.2093 - mae: 0.3573 - val_loss: 0.5340 - val_mae: 0.6562 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1893 - mae: 0.3423 - val_loss: 0.6251 - val_mae: 0.6940 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1893 - mae: 0.3423 - val_loss: 0.6251 - val_mae: 0.6940 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1800 - mae: 0.3335 - val_loss: 0.5499 - val_mae: 0.6579 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1800 - mae: 0.3335 - val_loss: 0.5499 - val_mae: 0.6579 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1617 - mae: 0.3130 - val_loss: 0.5881 - val_mae: 0.6814 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1617 - mae: 0.3130 - val_loss: 0.5881 - val_mae: 0.6814 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.1527 - mae: 0.3029 - val_loss: 0.5792 - val_mae: 0.6752 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.1527 - mae: 0.3029 - val_loss: 0.5792 - val_mae: 0.6752 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1498 - mae: 0.3029 - val_loss: 0.5941 - val_mae: 0.6830 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1498 - mae: 0.3029 - val_loss: 0.5941 - val_mae: 0.6830 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1567 - mae: 0.3057 - val_loss: 0.5881 - val_mae: 0.6748 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1567 - mae: 0.3057 - val_loss: 0.5881 - val_mae: 0.6748 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1442 - mae: 0.2960 - val_loss: 0.6208 - val_mae: 0.7046 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1442 - mae: 0.2960 - val_loss: 0.6208 - val_mae: 0.7046 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1373 - mae: 0.2878 - val_loss: 0.6654 - val_mae: 0.7392 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1373 - mae: 0.2878 - val_loss: 0.6654 - val_mae: 0.7392 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1380 - mae: 0.2874 - val_loss: 0.7145 - val_mae: 0.7619 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1380 - mae: 0.2874 - val_loss: 0.7145 - val_mae: 0.7619 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1379 - mae: 0.2927 - val_loss: 0.6530 - val_mae: 0.7341 - learning_rate: 2.5000e-04\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1379 - mae: 0.2927 - val_loss: 0.6530 - val_mae: 0.7341 - learning_rate: 2.5000e-04\n",
      "Fold 3 MSE: 0.533959\n",
      "Fold 3 MSE: 0.533959\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 0.8278 - mae: 0.7107 - val_loss: 0.7635 - val_mae: 0.8297 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 0.8278 - mae: 0.7107 - val_loss: 0.7635 - val_mae: 0.8297 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5760 - mae: 0.6022 - val_loss: 0.5689 - val_mae: 0.6989 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5760 - mae: 0.6022 - val_loss: 0.5689 - val_mae: 0.6989 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4053 - mae: 0.5021 - val_loss: 0.3650 - val_mae: 0.5314 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4053 - mae: 0.5021 - val_loss: 0.3650 - val_mae: 0.5314 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3543 - mae: 0.4712 - val_loss: 0.2657 - val_mae: 0.4332 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3543 - mae: 0.4712 - val_loss: 0.2657 - val_mae: 0.4332 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2901 - mae: 0.4243 - val_loss: 0.2454 - val_mae: 0.3865 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2901 - mae: 0.4243 - val_loss: 0.2454 - val_mae: 0.3865 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2551 - mae: 0.3938 - val_loss: 0.1155 - val_mae: 0.2641 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2551 - mae: 0.3938 - val_loss: 0.1155 - val_mae: 0.2641 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2305 - mae: 0.3786 - val_loss: 0.1609 - val_mae: 0.2951 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2305 - mae: 0.3786 - val_loss: 0.1609 - val_mae: 0.2951 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2028 - mae: 0.3539 - val_loss: 0.1012 - val_mae: 0.2447 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2028 - mae: 0.3539 - val_loss: 0.1012 - val_mae: 0.2447 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1725 - mae: 0.3274 - val_loss: 0.0595 - val_mae: 0.1884 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1725 - mae: 0.3274 - val_loss: 0.0595 - val_mae: 0.1884 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1506 - mae: 0.3030 - val_loss: 0.0530 - val_mae: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.1506 - mae: 0.3030 - val_loss: 0.0530 - val_mae: 0.1749 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.1366 - mae: 0.2851 - val_loss: 0.0512 - val_mae: 0.1747 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 0.1366 - mae: 0.2851 - val_loss: 0.0512 - val_mae: 0.1747 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.1231 - mae: 0.2783 - val_loss: 0.0597 - val_mae: 0.1849 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - loss: 0.1231 - mae: 0.2783 - val_loss: 0.0597 - val_mae: 0.1849 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 0.1044 - mae: 0.2562 - val_loss: 0.0627 - val_mae: 0.1894 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - loss: 0.1044 - mae: 0.2562 - val_loss: 0.0627 - val_mae: 0.1894 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - loss: 0.0981 - mae: 0.2475 - val_loss: 0.0556 - val_mae: 0.1796 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - loss: 0.0981 - mae: 0.2475 - val_loss: 0.0556 - val_mae: 0.1796 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 0.0913 - mae: 0.2364 - val_loss: 0.0640 - val_mae: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - loss: 0.0913 - mae: 0.2364 - val_loss: 0.0640 - val_mae: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - loss: 0.0869 - mae: 0.2347 - val_loss: 0.0431 - val_mae: 0.1548 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - loss: 0.0869 - mae: 0.2347 - val_loss: 0.0431 - val_mae: 0.1548 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0802 - mae: 0.2235 - val_loss: 0.0403 - val_mae: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 0.0802 - mae: 0.2235 - val_loss: 0.0403 - val_mae: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 0.0756 - mae: 0.2163 - val_loss: 0.0496 - val_mae: 0.1695 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 0.0756 - mae: 0.2163 - val_loss: 0.0496 - val_mae: 0.1695 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - loss: 0.0711 - mae: 0.2097 - val_loss: 0.0537 - val_mae: 0.1752 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - loss: 0.0711 - mae: 0.2097 - val_loss: 0.0537 - val_mae: 0.1752 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 0.0674 - mae: 0.2068 - val_loss: 0.0446 - val_mae: 0.1606 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - loss: 0.0674 - mae: 0.2068 - val_loss: 0.0446 - val_mae: 0.1606 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.0599 - mae: 0.1946 - val_loss: 0.0483 - val_mae: 0.1683 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.0599 - mae: 0.1946 - val_loss: 0.0483 - val_mae: 0.1683 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - loss: 0.0578 - mae: 0.1873 - val_loss: 0.0519 - val_mae: 0.1725 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - loss: 0.0578 - mae: 0.1873 - val_loss: 0.0519 - val_mae: 0.1725 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - loss: 0.0555 - mae: 0.1866 - val_loss: 0.0462 - val_mae: 0.1634 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - loss: 0.0555 - mae: 0.1866 - val_loss: 0.0462 - val_mae: 0.1634 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0583 - mae: 0.1907 - val_loss: 0.0437 - val_mae: 0.1584 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.0583 - mae: 0.1907 - val_loss: 0.0437 - val_mae: 0.1584 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - loss: 0.0553 - mae: 0.1860 - val_loss: 0.0417 - val_mae: 0.1555 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - loss: 0.0553 - mae: 0.1860 - val_loss: 0.0417 - val_mae: 0.1555 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0510 - mae: 0.1780 - val_loss: 0.0418 - val_mae: 0.1550 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.0510 - mae: 0.1780 - val_loss: 0.0418 - val_mae: 0.1550 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 0.0529 - mae: 0.1811 - val_loss: 0.0407 - val_mae: 0.1535 - learning_rate: 5.0000e-04\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - loss: 0.0529 - mae: 0.1811 - val_loss: 0.0407 - val_mae: 0.1535 - learning_rate: 5.0000e-04\n",
      "Fold 4 MSE: 0.040285\n",
      "Fold 4 MSE: 0.040285\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 152ms/step - loss: 0.7582 - mae: 0.6762 - val_loss: 0.7691 - val_mae: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 152ms/step - loss: 0.7582 - mae: 0.6762 - val_loss: 0.7691 - val_mae: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.4905 - mae: 0.5528 - val_loss: 0.5445 - val_mae: 0.6807 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.4905 - mae: 0.5528 - val_loss: 0.5445 - val_mae: 0.6807 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.4223 - mae: 0.5092 - val_loss: 0.2934 - val_mae: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.4223 - mae: 0.5092 - val_loss: 0.2934 - val_mae: 0.4731 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.3459 - mae: 0.4592 - val_loss: 0.1833 - val_mae: 0.3490 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.3459 - mae: 0.4592 - val_loss: 0.1833 - val_mae: 0.3490 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 0.2994 - mae: 0.4262 - val_loss: 0.0457 - val_mae: 0.1715 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 0.2994 - mae: 0.4262 - val_loss: 0.0457 - val_mae: 0.1715 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.2467 - mae: 0.3882 - val_loss: 0.0227 - val_mae: 0.1272 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.2467 - mae: 0.3882 - val_loss: 0.0227 - val_mae: 0.1272 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.2039 - mae: 0.3553 - val_loss: 0.0153 - val_mae: 0.1048 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.2039 - mae: 0.3553 - val_loss: 0.0153 - val_mae: 0.1048 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.1680 - mae: 0.3227 - val_loss: 0.0304 - val_mae: 0.1472 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - loss: 0.1680 - mae: 0.3227 - val_loss: 0.0304 - val_mae: 0.1472 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.1509 - mae: 0.3066 - val_loss: 0.0381 - val_mae: 0.1654 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.1509 - mae: 0.3066 - val_loss: 0.0381 - val_mae: 0.1654 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.1356 - mae: 0.2915 - val_loss: 0.0364 - val_mae: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.1356 - mae: 0.2915 - val_loss: 0.0364 - val_mae: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.1187 - mae: 0.2715 - val_loss: 0.0171 - val_mae: 0.1041 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.1187 - mae: 0.2715 - val_loss: 0.0171 - val_mae: 0.1041 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.1002 - mae: 0.2477 - val_loss: 0.0363 - val_mae: 0.1589 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - loss: 0.1002 - mae: 0.2477 - val_loss: 0.0363 - val_mae: 0.1589 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - loss: 0.0989 - mae: 0.2500 - val_loss: 0.0314 - val_mae: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - loss: 0.0989 - mae: 0.2500 - val_loss: 0.0314 - val_mae: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.0932 - mae: 0.2435 - val_loss: 0.0183 - val_mae: 0.1111 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.0932 - mae: 0.2435 - val_loss: 0.0183 - val_mae: 0.1111 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0927 - mae: 0.2390 - val_loss: 0.0255 - val_mae: 0.1343 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0927 - mae: 0.2390 - val_loss: 0.0255 - val_mae: 0.1343 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0824 - mae: 0.2291 - val_loss: 0.0239 - val_mae: 0.1307 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 0.0824 - mae: 0.2291 - val_loss: 0.0239 - val_mae: 0.1307 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0858 - mae: 0.2317 - val_loss: 0.0259 - val_mae: 0.1348 - learning_rate: 5.0000e-04\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - loss: 0.0858 - mae: 0.2317 - val_loss: 0.0259 - val_mae: 0.1348 - learning_rate: 5.0000e-04\n",
      "Fold 5 MSE: 0.015349\n",
      "Fold 5 MSE: 0.015349\n",
      "Error processing ABT: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing ADBE...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Error processing ABT: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing ADBE...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 338ms/step - loss: 3.1650 - mae: 1.4772 - val_loss: 0.6691 - val_mae: 0.7717 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 338ms/step - loss: 3.1650 - mae: 1.4772 - val_loss: 0.6691 - val_mae: 0.7717 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.4616 - mae: 1.3667 - val_loss: 0.5391 - val_mae: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 2.4616 - mae: 1.3667 - val_loss: 0.5391 - val_mae: 0.6835 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 2.0166 - mae: 1.2372 - val_loss: 0.4147 - val_mae: 0.5880 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 2.0166 - mae: 1.2372 - val_loss: 0.4147 - val_mae: 0.5880 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 1.8686 - mae: 1.1905 - val_loss: 0.3206 - val_mae: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 1.8686 - mae: 1.1905 - val_loss: 0.3206 - val_mae: 0.5053 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 1.5273 - mae: 1.0671 - val_loss: 0.2457 - val_mae: 0.4375 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 1.5273 - mae: 1.0671 - val_loss: 0.2457 - val_mae: 0.4375 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 1.4428 - mae: 1.0079 - val_loss: 0.1646 - val_mae: 0.3609 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 1.4428 - mae: 1.0079 - val_loss: 0.1646 - val_mae: 0.3609 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 1.3160 - mae: 0.9607 - val_loss: 0.1118 - val_mae: 0.2958 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 1.3160 - mae: 0.9607 - val_loss: 0.1118 - val_mae: 0.2958 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1.2784 - mae: 0.8981 - val_loss: 0.0802 - val_mae: 0.2535 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1.2784 - mae: 0.8981 - val_loss: 0.0802 - val_mae: 0.2535 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 1.0457 - mae: 0.8499 - val_loss: 0.0676 - val_mae: 0.2046 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 1.0457 - mae: 0.8499 - val_loss: 0.0676 - val_mae: 0.2046 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.9712 - mae: 0.8132 - val_loss: 0.0807 - val_mae: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.9712 - mae: 0.8132 - val_loss: 0.0807 - val_mae: 0.2178 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.9177 - mae: 0.7982 - val_loss: 0.1103 - val_mae: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.9177 - mae: 0.7982 - val_loss: 0.1103 - val_mae: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.7432 - mae: 0.6914 - val_loss: 0.1989 - val_mae: 0.3585 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.7432 - mae: 0.6914 - val_loss: 0.1989 - val_mae: 0.3585 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.7716 - mae: 0.6706 - val_loss: 0.2525 - val_mae: 0.4212 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.7716 - mae: 0.6706 - val_loss: 0.2525 - val_mae: 0.4212 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.6951 - mae: 0.6647 - val_loss: 0.3684 - val_mae: 0.5370 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.6951 - mae: 0.6647 - val_loss: 0.3684 - val_mae: 0.5370 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.6455 - mae: 0.6221 - val_loss: 0.3436 - val_mae: 0.5113 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.6455 - mae: 0.6221 - val_loss: 0.3436 - val_mae: 0.5113 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.7101 - mae: 0.6457 - val_loss: 0.3562 - val_mae: 0.5187 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.7101 - mae: 0.6457 - val_loss: 0.3562 - val_mae: 0.5187 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.5518 - mae: 0.5862 - val_loss: 0.3912 - val_mae: 0.5494 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.5518 - mae: 0.5862 - val_loss: 0.3912 - val_mae: 0.5494 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.5395 - mae: 0.5739 - val_loss: 0.4158 - val_mae: 0.5732 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.5395 - mae: 0.5739 - val_loss: 0.4158 - val_mae: 0.5732 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.6248 - mae: 0.6048 - val_loss: 0.4006 - val_mae: 0.5593 - learning_rate: 5.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.6248 - mae: 0.6048 - val_loss: 0.4006 - val_mae: 0.5593 - learning_rate: 5.0000e-04\n",
      "Fold 1 MSE: 0.067613\n",
      "Fold 1 MSE: 0.067613\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - loss: 2.1064 - mae: 1.1960 - val_loss: 0.0741 - val_mae: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - loss: 2.1064 - mae: 1.1960 - val_loss: 0.0741 - val_mae: 0.2084 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.2548 - mae: 0.9380 - val_loss: 0.0924 - val_mae: 0.2615 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.2548 - mae: 0.9380 - val_loss: 0.0924 - val_mae: 0.2615 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.8847 - mae: 0.7541 - val_loss: 0.2222 - val_mae: 0.4148 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.8847 - mae: 0.7541 - val_loss: 0.2222 - val_mae: 0.4148 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.8573 - mae: 0.7395 - val_loss: 0.3366 - val_mae: 0.5304 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.8573 - mae: 0.7395 - val_loss: 0.3366 - val_mae: 0.5304 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.7531 - mae: 0.6954 - val_loss: 0.4558 - val_mae: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.7531 - mae: 0.6954 - val_loss: 0.4558 - val_mae: 0.6159 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.6266 - mae: 0.6266 - val_loss: 0.6118 - val_mae: 0.7243 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.6266 - mae: 0.6266 - val_loss: 0.6118 - val_mae: 0.7243 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.5030 - mae: 0.5636 - val_loss: 0.4852 - val_mae: 0.6459 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.5030 - mae: 0.5636 - val_loss: 0.4852 - val_mae: 0.6459 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.4853 - mae: 0.5409 - val_loss: 0.4229 - val_mae: 0.6183 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.4853 - mae: 0.5409 - val_loss: 0.4229 - val_mae: 0.6183 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4267 - mae: 0.5147 - val_loss: 0.3010 - val_mae: 0.5227 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4267 - mae: 0.5147 - val_loss: 0.3010 - val_mae: 0.5227 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4309 - mae: 0.5067 - val_loss: 0.2169 - val_mae: 0.4384 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4309 - mae: 0.5067 - val_loss: 0.2169 - val_mae: 0.4384 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.4065 - mae: 0.4879 - val_loss: 0.1901 - val_mae: 0.4063 - learning_rate: 5.0000e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.4065 - mae: 0.4879 - val_loss: 0.1901 - val_mae: 0.4063 - learning_rate: 5.0000e-04\n",
      "Fold 2 MSE: 0.074084\n",
      "Fold 2 MSE: 0.074084\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - loss: 1.2836 - mae: 0.9155 - val_loss: 1.4927 - val_mae: 1.1506 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - loss: 1.2836 - mae: 0.9155 - val_loss: 1.4927 - val_mae: 1.1506 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.7021 - mae: 0.6663 - val_loss: 1.6875 - val_mae: 1.2136 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.7021 - mae: 0.6663 - val_loss: 1.6875 - val_mae: 1.2136 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.5219 - mae: 0.5543 - val_loss: 1.8153 - val_mae: 1.2582 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.5219 - mae: 0.5543 - val_loss: 1.8153 - val_mae: 1.2582 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.4788 - mae: 0.5196 - val_loss: 1.8327 - val_mae: 1.2893 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.4788 - mae: 0.5196 - val_loss: 1.8327 - val_mae: 1.2893 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.4042 - mae: 0.4722 - val_loss: 1.8429 - val_mae: 1.2918 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.4042 - mae: 0.4722 - val_loss: 1.8429 - val_mae: 1.2918 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3530 - mae: 0.4549 - val_loss: 2.1644 - val_mae: 1.4158 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3530 - mae: 0.4549 - val_loss: 2.1644 - val_mae: 1.4158 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.3177 - mae: 0.4286 - val_loss: 2.1947 - val_mae: 1.4086 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.3177 - mae: 0.4286 - val_loss: 2.1947 - val_mae: 1.4086 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3075 - mae: 0.4254 - val_loss: 2.2086 - val_mae: 1.4072 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3075 - mae: 0.4254 - val_loss: 2.2086 - val_mae: 1.4072 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2838 - mae: 0.4171 - val_loss: 1.9279 - val_mae: 1.3277 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.2838 - mae: 0.4171 - val_loss: 1.9279 - val_mae: 1.3277 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2533 - mae: 0.3904 - val_loss: 1.8295 - val_mae: 1.2813 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2533 - mae: 0.3904 - val_loss: 1.8295 - val_mae: 1.2813 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.2645 - mae: 0.4034 - val_loss: 1.5143 - val_mae: 1.1744 - learning_rate: 5.0000e-04\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.2645 - mae: 0.4034 - val_loss: 1.5143 - val_mae: 1.1744 - learning_rate: 5.0000e-04\n",
      "Fold 3 MSE: 1.492746\n",
      "Fold 3 MSE: 1.492746\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 0.8263 - mae: 0.7036 - val_loss: 0.5872 - val_mae: 0.6373 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 0.8263 - mae: 0.7036 - val_loss: 0.5872 - val_mae: 0.6373 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.5538 - mae: 0.5804 - val_loss: 0.6227 - val_mae: 0.6795 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.5538 - mae: 0.5804 - val_loss: 0.6227 - val_mae: 0.6795 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.4621 - mae: 0.5241 - val_loss: 0.4328 - val_mae: 0.5586 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.4621 - mae: 0.5241 - val_loss: 0.4328 - val_mae: 0.5586 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.4436 - mae: 0.5167 - val_loss: 0.2278 - val_mae: 0.3745 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.4436 - mae: 0.5167 - val_loss: 0.2278 - val_mae: 0.3745 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.3606 - mae: 0.4588 - val_loss: 0.1715 - val_mae: 0.3190 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.3606 - mae: 0.4588 - val_loss: 0.1715 - val_mae: 0.3190 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3066 - mae: 0.4263 - val_loss: 0.1757 - val_mae: 0.3344 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.3066 - mae: 0.4263 - val_loss: 0.1757 - val_mae: 0.3344 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2720 - mae: 0.4055 - val_loss: 0.1128 - val_mae: 0.2651 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2720 - mae: 0.4055 - val_loss: 0.1128 - val_mae: 0.2651 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2481 - mae: 0.3838 - val_loss: 0.1117 - val_mae: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2481 - mae: 0.3838 - val_loss: 0.1117 - val_mae: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2169 - mae: 0.3579 - val_loss: 0.0957 - val_mae: 0.2412 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2169 - mae: 0.3579 - val_loss: 0.0957 - val_mae: 0.2412 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2021 - mae: 0.3425 - val_loss: 0.0926 - val_mae: 0.2420 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.2021 - mae: 0.3425 - val_loss: 0.0926 - val_mae: 0.2420 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1924 - mae: 0.3274 - val_loss: 0.1430 - val_mae: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1924 - mae: 0.3274 - val_loss: 0.1430 - val_mae: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1499 - mae: 0.2977 - val_loss: 0.1125 - val_mae: 0.2562 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1499 - mae: 0.2977 - val_loss: 0.1125 - val_mae: 0.2562 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1434 - mae: 0.2936 - val_loss: 0.1168 - val_mae: 0.2706 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1434 - mae: 0.2936 - val_loss: 0.1168 - val_mae: 0.2706 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1331 - mae: 0.2808 - val_loss: 0.1806 - val_mae: 0.3380 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1331 - mae: 0.2808 - val_loss: 0.1806 - val_mae: 0.3380 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1197 - mae: 0.2700 - val_loss: 0.1698 - val_mae: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1197 - mae: 0.2700 - val_loss: 0.1698 - val_mae: 0.3191 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1089 - mae: 0.2585 - val_loss: 0.1075 - val_mae: 0.2357 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1089 - mae: 0.2585 - val_loss: 0.1075 - val_mae: 0.2357 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1091 - mae: 0.2555 - val_loss: 0.1359 - val_mae: 0.2793 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1091 - mae: 0.2555 - val_loss: 0.1359 - val_mae: 0.2793 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0989 - mae: 0.2440 - val_loss: 0.1320 - val_mae: 0.2694 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0989 - mae: 0.2440 - val_loss: 0.1320 - val_mae: 0.2694 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0934 - mae: 0.2364 - val_loss: 0.1147 - val_mae: 0.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0934 - mae: 0.2364 - val_loss: 0.1147 - val_mae: 0.2476 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0913 - mae: 0.2321 - val_loss: 0.1249 - val_mae: 0.2630 - learning_rate: 5.0000e-04\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0913 - mae: 0.2321 - val_loss: 0.1249 - val_mae: 0.2630 - learning_rate: 5.0000e-04\n",
      "Fold 4 MSE: 0.092551\n",
      "Fold 4 MSE: 0.092551\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.7985 - mae: 0.6912 - val_loss: 1.1283 - val_mae: 1.0295 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 0.7985 - mae: 0.6912 - val_loss: 1.1283 - val_mae: 1.0295 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.5596 - mae: 0.5883 - val_loss: 0.5929 - val_mae: 0.7145 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.5596 - mae: 0.5883 - val_loss: 0.5929 - val_mae: 0.7145 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.4335 - mae: 0.5223 - val_loss: 0.4987 - val_mae: 0.6903 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.4335 - mae: 0.5223 - val_loss: 0.4987 - val_mae: 0.6903 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.3721 - mae: 0.4773 - val_loss: 0.2787 - val_mae: 0.5075 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.3721 - mae: 0.4773 - val_loss: 0.2787 - val_mae: 0.5075 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.2964 - mae: 0.4223 - val_loss: 0.1743 - val_mae: 0.3859 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.2964 - mae: 0.4223 - val_loss: 0.1743 - val_mae: 0.3859 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.2860 - mae: 0.4131 - val_loss: 0.1660 - val_mae: 0.3546 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.2860 - mae: 0.4131 - val_loss: 0.1660 - val_mae: 0.3546 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2173 - mae: 0.3698 - val_loss: 0.0803 - val_mae: 0.2282 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2173 - mae: 0.3698 - val_loss: 0.0803 - val_mae: 0.2282 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1854 - mae: 0.3358 - val_loss: 0.1039 - val_mae: 0.2539 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.1854 - mae: 0.3358 - val_loss: 0.1039 - val_mae: 0.2539 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1612 - mae: 0.3190 - val_loss: 0.0868 - val_mae: 0.2250 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1612 - mae: 0.3190 - val_loss: 0.0868 - val_mae: 0.2250 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1428 - mae: 0.2964 - val_loss: 0.0905 - val_mae: 0.2259 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.1428 - mae: 0.2964 - val_loss: 0.0905 - val_mae: 0.2259 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1187 - mae: 0.2728 - val_loss: 0.0768 - val_mae: 0.2049 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1187 - mae: 0.2728 - val_loss: 0.0768 - val_mae: 0.2049 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.1124 - mae: 0.2629 - val_loss: 0.0729 - val_mae: 0.1983 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.1124 - mae: 0.2629 - val_loss: 0.0729 - val_mae: 0.1983 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1000 - mae: 0.2503 - val_loss: 0.0727 - val_mae: 0.2058 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1000 - mae: 0.2503 - val_loss: 0.0727 - val_mae: 0.2058 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0915 - mae: 0.2414 - val_loss: 0.0582 - val_mae: 0.1852 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0915 - mae: 0.2414 - val_loss: 0.0582 - val_mae: 0.1852 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0839 - mae: 0.2299 - val_loss: 0.0610 - val_mae: 0.1869 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0839 - mae: 0.2299 - val_loss: 0.0610 - val_mae: 0.1869 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0801 - mae: 0.2235 - val_loss: 0.0596 - val_mae: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0801 - mae: 0.2235 - val_loss: 0.0596 - val_mae: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0706 - mae: 0.2084 - val_loss: 0.0643 - val_mae: 0.1951 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0706 - mae: 0.2084 - val_loss: 0.0643 - val_mae: 0.1951 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0663 - mae: 0.2015 - val_loss: 0.0564 - val_mae: 0.1735 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0663 - mae: 0.2015 - val_loss: 0.0564 - val_mae: 0.1735 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0623 - mae: 0.1948 - val_loss: 0.0584 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0623 - mae: 0.1948 - val_loss: 0.0584 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0607 - mae: 0.1955 - val_loss: 0.0454 - val_mae: 0.1623 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0607 - mae: 0.1955 - val_loss: 0.0454 - val_mae: 0.1623 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0583 - mae: 0.1897 - val_loss: 0.0541 - val_mae: 0.1732 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0583 - mae: 0.1897 - val_loss: 0.0541 - val_mae: 0.1732 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0589 - mae: 0.1919 - val_loss: 0.0432 - val_mae: 0.1564 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0589 - mae: 0.1919 - val_loss: 0.0432 - val_mae: 0.1564 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0557 - mae: 0.1860 - val_loss: 0.0452 - val_mae: 0.1596 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0557 - mae: 0.1860 - val_loss: 0.0452 - val_mae: 0.1596 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0517 - mae: 0.1805 - val_loss: 0.0456 - val_mae: 0.1597 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0517 - mae: 0.1805 - val_loss: 0.0456 - val_mae: 0.1597 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0518 - mae: 0.1818 - val_loss: 0.0485 - val_mae: 0.1754 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0518 - mae: 0.1818 - val_loss: 0.0485 - val_mae: 0.1754 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0511 - mae: 0.1778 - val_loss: 0.0497 - val_mae: 0.1678 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0511 - mae: 0.1778 - val_loss: 0.0497 - val_mae: 0.1678 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0485 - mae: 0.1733 - val_loss: 0.0505 - val_mae: 0.1647 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0485 - mae: 0.1733 - val_loss: 0.0505 - val_mae: 0.1647 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0482 - mae: 0.1745 - val_loss: 0.0407 - val_mae: 0.1517 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0482 - mae: 0.1745 - val_loss: 0.0407 - val_mae: 0.1517 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0483 - mae: 0.1732 - val_loss: 0.0411 - val_mae: 0.1611 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0483 - mae: 0.1732 - val_loss: 0.0411 - val_mae: 0.1611 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0477 - mae: 0.1759 - val_loss: 0.0397 - val_mae: 0.1469 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0477 - mae: 0.1759 - val_loss: 0.0397 - val_mae: 0.1469 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0476 - mae: 0.1725 - val_loss: 0.0380 - val_mae: 0.1507 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0476 - mae: 0.1725 - val_loss: 0.0380 - val_mae: 0.1507 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0460 - mae: 0.1685 - val_loss: 0.0406 - val_mae: 0.1509 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0460 - mae: 0.1685 - val_loss: 0.0406 - val_mae: 0.1509 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0474 - mae: 0.1711 - val_loss: 0.0362 - val_mae: 0.1434 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0474 - mae: 0.1711 - val_loss: 0.0362 - val_mae: 0.1434 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0463 - mae: 0.1702 - val_loss: 0.0388 - val_mae: 0.1449 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0463 - mae: 0.1702 - val_loss: 0.0388 - val_mae: 0.1449 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0466 - mae: 0.1714 - val_loss: 0.0397 - val_mae: 0.1503 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0466 - mae: 0.1714 - val_loss: 0.0397 - val_mae: 0.1503 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0460 - mae: 0.1692 - val_loss: 0.0394 - val_mae: 0.1497 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0460 - mae: 0.1692 - val_loss: 0.0394 - val_mae: 0.1497 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0444 - mae: 0.1658 - val_loss: 0.0387 - val_mae: 0.1479 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0444 - mae: 0.1658 - val_loss: 0.0387 - val_mae: 0.1479 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0463 - mae: 0.1686 - val_loss: 0.0380 - val_mae: 0.1437 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0463 - mae: 0.1686 - val_loss: 0.0380 - val_mae: 0.1437 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0441 - mae: 0.1657 - val_loss: 0.0416 - val_mae: 0.1513 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0441 - mae: 0.1657 - val_loss: 0.0416 - val_mae: 0.1513 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0431 - mae: 0.1647 - val_loss: 0.0418 - val_mae: 0.1507 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0431 - mae: 0.1647 - val_loss: 0.0418 - val_mae: 0.1507 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0429 - mae: 0.1642 - val_loss: 0.0410 - val_mae: 0.1507 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0429 - mae: 0.1642 - val_loss: 0.0410 - val_mae: 0.1507 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0448 - mae: 0.1656 - val_loss: 0.0422 - val_mae: 0.1565 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0448 - mae: 0.1656 - val_loss: 0.0422 - val_mae: 0.1565 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0432 - mae: 0.1639 - val_loss: 0.0418 - val_mae: 0.1515 - learning_rate: 2.5000e-04\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0432 - mae: 0.1639 - val_loss: 0.0418 - val_mae: 0.1515 - learning_rate: 2.5000e-04\n",
      "Fold 5 MSE: 0.036220\n",
      "Fold 5 MSE: 0.036220\n",
      "Error processing ADBE: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing AMGN...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Error processing ADBE: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing AMGN...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 2.6138 - mae: 1.3564 - val_loss: 0.6467 - val_mae: 0.7813 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 2.6138 - mae: 1.3564 - val_loss: 0.6467 - val_mae: 0.7813 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8469 - mae: 1.1699 - val_loss: 0.4711 - val_mae: 0.6558 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 1.8469 - mae: 1.1699 - val_loss: 0.4711 - val_mae: 0.6558 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1.6832 - mae: 1.1119 - val_loss: 0.3681 - val_mae: 0.5747 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 1.6832 - mae: 1.1119 - val_loss: 0.3681 - val_mae: 0.5747 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 1.4700 - mae: 1.0506 - val_loss: 0.2857 - val_mae: 0.5014 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 1.4700 - mae: 1.0506 - val_loss: 0.2857 - val_mae: 0.5014 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 1.2906 - mae: 0.9573 - val_loss: 0.1865 - val_mae: 0.3852 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 1.2906 - mae: 0.9573 - val_loss: 0.1865 - val_mae: 0.3852 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 1.1239 - mae: 0.8710 - val_loss: 0.1308 - val_mae: 0.3128 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 1.1239 - mae: 0.8710 - val_loss: 0.1308 - val_mae: 0.3128 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 1.0023 - mae: 0.8157 - val_loss: 0.0860 - val_mae: 0.2442 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 1.0023 - mae: 0.8157 - val_loss: 0.0860 - val_mae: 0.2442 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.8894 - mae: 0.7761 - val_loss: 0.0491 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.8894 - mae: 0.7761 - val_loss: 0.0491 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.7437 - mae: 0.7023 - val_loss: 0.0396 - val_mae: 0.1668 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.7437 - mae: 0.7023 - val_loss: 0.0396 - val_mae: 0.1668 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.8557 - mae: 0.7513 - val_loss: 0.0320 - val_mae: 0.1556 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.8557 - mae: 0.7513 - val_loss: 0.0320 - val_mae: 0.1556 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.7179 - mae: 0.6813 - val_loss: 0.0289 - val_mae: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.7179 - mae: 0.6813 - val_loss: 0.0289 - val_mae: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.7113 - mae: 0.6645 - val_loss: 0.0341 - val_mae: 0.1469 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.7113 - mae: 0.6645 - val_loss: 0.0341 - val_mae: 0.1469 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.7296 - mae: 0.6609 - val_loss: 0.0379 - val_mae: 0.1571 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.7296 - mae: 0.6609 - val_loss: 0.0379 - val_mae: 0.1571 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5736 - mae: 0.5942 - val_loss: 0.0659 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.5736 - mae: 0.5942 - val_loss: 0.0659 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.5695 - mae: 0.5926 - val_loss: 0.0928 - val_mae: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.5695 - mae: 0.5926 - val_loss: 0.0928 - val_mae: 0.2533 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.4449 - mae: 0.5369 - val_loss: 0.0971 - val_mae: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.4449 - mae: 0.5369 - val_loss: 0.0971 - val_mae: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.4592 - mae: 0.5186 - val_loss: 0.0984 - val_mae: 0.2596 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.4592 - mae: 0.5186 - val_loss: 0.0984 - val_mae: 0.2596 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.4076 - mae: 0.4989 - val_loss: 0.1005 - val_mae: 0.2604 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.4076 - mae: 0.4989 - val_loss: 0.1005 - val_mae: 0.2604 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.4283 - mae: 0.5023 - val_loss: 0.0914 - val_mae: 0.2399 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.4283 - mae: 0.5023 - val_loss: 0.0914 - val_mae: 0.2399 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.4405 - mae: 0.5025 - val_loss: 0.1043 - val_mae: 0.2589 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.4405 - mae: 0.5025 - val_loss: 0.1043 - val_mae: 0.2589 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.4611 - mae: 0.5371 - val_loss: 0.1199 - val_mae: 0.2775 - learning_rate: 5.0000e-04\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.4611 - mae: 0.5371 - val_loss: 0.1199 - val_mae: 0.2775 - learning_rate: 5.0000e-04\n",
      "Fold 1 MSE: 0.028900\n",
      "Fold 1 MSE: 0.028900\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 2/5\n",
      "Training set shape: X=(730, 60, 8), y=(730, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 97ms/step - loss: 1.5460 - mae: 1.0321 - val_loss: 0.1454 - val_mae: 0.3344 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 97ms/step - loss: 1.5460 - mae: 1.0321 - val_loss: 0.1454 - val_mae: 0.3344 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.1242 - mae: 0.8840 - val_loss: 0.0814 - val_mae: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 1.1242 - mae: 0.8840 - val_loss: 0.0814 - val_mae: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.8860 - mae: 0.7639 - val_loss: 0.0825 - val_mae: 0.2292 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.8860 - mae: 0.7639 - val_loss: 0.0825 - val_mae: 0.2292 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.6637 - mae: 0.6618 - val_loss: 0.0859 - val_mae: 0.2276 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.6637 - mae: 0.6618 - val_loss: 0.0859 - val_mae: 0.2276 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6385 - mae: 0.6430 - val_loss: 0.1130 - val_mae: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.6385 - mae: 0.6430 - val_loss: 0.1130 - val_mae: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.5022 - mae: 0.5515 - val_loss: 0.1477 - val_mae: 0.2904 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.5022 - mae: 0.5515 - val_loss: 0.1477 - val_mae: 0.2904 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.4327 - mae: 0.5150 - val_loss: 0.1510 - val_mae: 0.3058 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.4327 - mae: 0.5150 - val_loss: 0.1510 - val_mae: 0.3058 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.3855 - mae: 0.4817 - val_loss: 0.1617 - val_mae: 0.3080 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.3855 - mae: 0.4817 - val_loss: 0.1617 - val_mae: 0.3080 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.3398 - mae: 0.4516 - val_loss: 0.1706 - val_mae: 0.3412 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.3398 - mae: 0.4516 - val_loss: 0.1706 - val_mae: 0.3412 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.3301 - mae: 0.4377 - val_loss: 0.1457 - val_mae: 0.2961 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.3301 - mae: 0.4377 - val_loss: 0.1457 - val_mae: 0.2961 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.3209 - mae: 0.4319 - val_loss: 0.1575 - val_mae: 0.3049 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.3209 - mae: 0.4319 - val_loss: 0.1575 - val_mae: 0.3049 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.2951 - mae: 0.4178 - val_loss: 0.1377 - val_mae: 0.2867 - learning_rate: 5.0000e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.2951 - mae: 0.4178 - val_loss: 0.1377 - val_mae: 0.2867 - learning_rate: 5.0000e-04\n",
      "Fold 2 MSE: 0.081415\n",
      "Fold 2 MSE: 0.081415\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 3/5\n",
      "Training set shape: X=(1125, 60, 8), y=(1125, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 76ms/step - loss: 1.3124 - mae: 0.9106 - val_loss: 0.2729 - val_mae: 0.4808 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 76ms/step - loss: 1.3124 - mae: 0.9106 - val_loss: 0.2729 - val_mae: 0.4808 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.7956 - mae: 0.7060 - val_loss: 0.4114 - val_mae: 0.6076 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.7956 - mae: 0.7060 - val_loss: 0.4114 - val_mae: 0.6076 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5463 - mae: 0.5825 - val_loss: 0.5840 - val_mae: 0.7416 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5463 - mae: 0.5825 - val_loss: 0.5840 - val_mae: 0.7416 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.4452 - mae: 0.5241 - val_loss: 0.5440 - val_mae: 0.7048 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.4452 - mae: 0.5241 - val_loss: 0.5440 - val_mae: 0.7048 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4050 - mae: 0.4971 - val_loss: 0.4535 - val_mae: 0.6401 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.4050 - mae: 0.4971 - val_loss: 0.4535 - val_mae: 0.6401 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4055 - mae: 0.4841 - val_loss: 0.3591 - val_mae: 0.5673 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4055 - mae: 0.4841 - val_loss: 0.3591 - val_mae: 0.5673 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.3326 - mae: 0.4423 - val_loss: 0.2606 - val_mae: 0.4627 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.3326 - mae: 0.4423 - val_loss: 0.2606 - val_mae: 0.4627 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3157 - mae: 0.4344 - val_loss: 0.1735 - val_mae: 0.3668 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3157 - mae: 0.4344 - val_loss: 0.1735 - val_mae: 0.3668 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.3127 - mae: 0.4260 - val_loss: 0.1122 - val_mae: 0.2825 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.3127 - mae: 0.4260 - val_loss: 0.1122 - val_mae: 0.2825 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2709 - mae: 0.3942 - val_loss: 0.0781 - val_mae: 0.2299 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2709 - mae: 0.3942 - val_loss: 0.0781 - val_mae: 0.2299 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2560 - mae: 0.3892 - val_loss: 0.0586 - val_mae: 0.1958 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.2560 - mae: 0.3892 - val_loss: 0.0586 - val_mae: 0.1958 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2491 - mae: 0.3793 - val_loss: 0.0508 - val_mae: 0.1833 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.2491 - mae: 0.3793 - val_loss: 0.0508 - val_mae: 0.1833 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2545 - mae: 0.3857 - val_loss: 0.0504 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2545 - mae: 0.3857 - val_loss: 0.0504 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2269 - mae: 0.3716 - val_loss: 0.0421 - val_mae: 0.1689 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2269 - mae: 0.3716 - val_loss: 0.0421 - val_mae: 0.1689 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2124 - mae: 0.3545 - val_loss: 0.0462 - val_mae: 0.1690 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2124 - mae: 0.3545 - val_loss: 0.0462 - val_mae: 0.1690 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2051 - mae: 0.3504 - val_loss: 0.0430 - val_mae: 0.1612 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2051 - mae: 0.3504 - val_loss: 0.0430 - val_mae: 0.1612 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1957 - mae: 0.3433 - val_loss: 0.0374 - val_mae: 0.1559 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1957 - mae: 0.3433 - val_loss: 0.0374 - val_mae: 0.1559 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1692 - mae: 0.3234 - val_loss: 0.0559 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1692 - mae: 0.3234 - val_loss: 0.0559 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.1713 - mae: 0.3172 - val_loss: 0.0470 - val_mae: 0.1699 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.1713 - mae: 0.3172 - val_loss: 0.0470 - val_mae: 0.1699 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1531 - mae: 0.2999 - val_loss: 0.0396 - val_mae: 0.1579 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1531 - mae: 0.2999 - val_loss: 0.0396 - val_mae: 0.1579 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.1634 - mae: 0.3073 - val_loss: 0.0714 - val_mae: 0.1985 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.1634 - mae: 0.3073 - val_loss: 0.0714 - val_mae: 0.1985 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1577 - mae: 0.3032 - val_loss: 0.0537 - val_mae: 0.1826 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1577 - mae: 0.3032 - val_loss: 0.0537 - val_mae: 0.1826 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1268 - mae: 0.2752 - val_loss: 0.0628 - val_mae: 0.1984 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1268 - mae: 0.2752 - val_loss: 0.0628 - val_mae: 0.1984 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1370 - mae: 0.2847 - val_loss: 0.0562 - val_mae: 0.1921 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1370 - mae: 0.2847 - val_loss: 0.0562 - val_mae: 0.1921 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1298 - mae: 0.2763 - val_loss: 0.0636 - val_mae: 0.2045 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.1298 - mae: 0.2763 - val_loss: 0.0636 - val_mae: 0.2045 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1343 - mae: 0.2782 - val_loss: 0.0744 - val_mae: 0.2233 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.1343 - mae: 0.2782 - val_loss: 0.0744 - val_mae: 0.2233 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1324 - mae: 0.2843 - val_loss: 0.0634 - val_mae: 0.2111 - learning_rate: 2.5000e-04\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1324 - mae: 0.2843 - val_loss: 0.0634 - val_mae: 0.2111 - learning_rate: 2.5000e-04\n",
      "Fold 3 MSE: 0.037365\n",
      "Fold 3 MSE: 0.037365\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "\n",
      "Fold 4/5\n",
      "Training set shape: X=(1520, 60, 8), y=(1520, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - loss: 0.9097 - mae: 0.7399 - val_loss: 0.8352 - val_mae: 0.8678 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - loss: 0.9097 - mae: 0.7399 - val_loss: 0.8352 - val_mae: 0.8678 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.5212 - mae: 0.5574 - val_loss: 1.0962 - val_mae: 1.0157 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.5212 - mae: 0.5574 - val_loss: 1.0962 - val_mae: 1.0157 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3907 - mae: 0.4826 - val_loss: 1.0477 - val_mae: 0.9946 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.3907 - mae: 0.4826 - val_loss: 1.0477 - val_mae: 0.9946 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3618 - mae: 0.4693 - val_loss: 0.7963 - val_mae: 0.8573 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3618 - mae: 0.4693 - val_loss: 0.7963 - val_mae: 0.8573 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.3005 - mae: 0.4261 - val_loss: 0.5394 - val_mae: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.3005 - mae: 0.4261 - val_loss: 0.5394 - val_mae: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2598 - mae: 0.3975 - val_loss: 0.3436 - val_mae: 0.5275 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.2598 - mae: 0.3975 - val_loss: 0.3436 - val_mae: 0.5275 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2025 - mae: 0.3504 - val_loss: 0.3734 - val_mae: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.2025 - mae: 0.3504 - val_loss: 0.3734 - val_mae: 0.5604 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1994 - mae: 0.3478 - val_loss: 0.2674 - val_mae: 0.4800 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1994 - mae: 0.3478 - val_loss: 0.2674 - val_mae: 0.4800 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1739 - mae: 0.3271 - val_loss: 0.1352 - val_mae: 0.3163 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1739 - mae: 0.3271 - val_loss: 0.1352 - val_mae: 0.3163 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1446 - mae: 0.2989 - val_loss: 0.1145 - val_mae: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.1446 - mae: 0.2989 - val_loss: 0.1145 - val_mae: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1294 - mae: 0.2866 - val_loss: 0.1323 - val_mae: 0.3033 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.1294 - mae: 0.2866 - val_loss: 0.1323 - val_mae: 0.3033 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1110 - mae: 0.2606 - val_loss: 0.0820 - val_mae: 0.2205 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.1110 - mae: 0.2606 - val_loss: 0.0820 - val_mae: 0.2205 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1034 - mae: 0.2516 - val_loss: 0.0937 - val_mae: 0.2254 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.1034 - mae: 0.2516 - val_loss: 0.0937 - val_mae: 0.2254 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0928 - mae: 0.2376 - val_loss: 0.1106 - val_mae: 0.2515 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0928 - mae: 0.2376 - val_loss: 0.1106 - val_mae: 0.2515 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0811 - mae: 0.2244 - val_loss: 0.0941 - val_mae: 0.2292 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0811 - mae: 0.2244 - val_loss: 0.0941 - val_mae: 0.2292 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0764 - mae: 0.2161 - val_loss: 0.0761 - val_mae: 0.2119 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0764 - mae: 0.2161 - val_loss: 0.0761 - val_mae: 0.2119 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0683 - mae: 0.2075 - val_loss: 0.0751 - val_mae: 0.2045 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0683 - mae: 0.2075 - val_loss: 0.0751 - val_mae: 0.2045 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0627 - mae: 0.1953 - val_loss: 0.0840 - val_mae: 0.2190 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0627 - mae: 0.1953 - val_loss: 0.0840 - val_mae: 0.2190 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0556 - mae: 0.1834 - val_loss: 0.0772 - val_mae: 0.2151 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0556 - mae: 0.1834 - val_loss: 0.0772 - val_mae: 0.2151 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0540 - mae: 0.1835 - val_loss: 0.0828 - val_mae: 0.2196 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0540 - mae: 0.1835 - val_loss: 0.0828 - val_mae: 0.2196 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0463 - mae: 0.1692 - val_loss: 0.0678 - val_mae: 0.1919 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0463 - mae: 0.1692 - val_loss: 0.0678 - val_mae: 0.1919 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0428 - mae: 0.1631 - val_loss: 0.0641 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0428 - mae: 0.1631 - val_loss: 0.0641 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0424 - mae: 0.1628 - val_loss: 0.0646 - val_mae: 0.1862 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0424 - mae: 0.1628 - val_loss: 0.0646 - val_mae: 0.1862 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0389 - mae: 0.1549 - val_loss: 0.0762 - val_mae: 0.2044 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0389 - mae: 0.1549 - val_loss: 0.0762 - val_mae: 0.2044 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0366 - mae: 0.1500 - val_loss: 0.0644 - val_mae: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0366 - mae: 0.1500 - val_loss: 0.0644 - val_mae: 0.1885 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0311 - mae: 0.1399 - val_loss: 0.0682 - val_mae: 0.1971 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0311 - mae: 0.1399 - val_loss: 0.0682 - val_mae: 0.1971 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0326 - mae: 0.1427 - val_loss: 0.0679 - val_mae: 0.1905 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0326 - mae: 0.1427 - val_loss: 0.0679 - val_mae: 0.1905 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0321 - mae: 0.1401 - val_loss: 0.0650 - val_mae: 0.1891 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0321 - mae: 0.1401 - val_loss: 0.0650 - val_mae: 0.1891 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0300 - mae: 0.1368 - val_loss: 0.0588 - val_mae: 0.1794 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0300 - mae: 0.1368 - val_loss: 0.0588 - val_mae: 0.1794 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0295 - mae: 0.1352 - val_loss: 0.0596 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0295 - mae: 0.1352 - val_loss: 0.0596 - val_mae: 0.1806 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0286 - mae: 0.1345 - val_loss: 0.0546 - val_mae: 0.1711 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0286 - mae: 0.1345 - val_loss: 0.0546 - val_mae: 0.1711 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0283 - mae: 0.1320 - val_loss: 0.0516 - val_mae: 0.1642 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0283 - mae: 0.1320 - val_loss: 0.0516 - val_mae: 0.1642 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0282 - mae: 0.1321 - val_loss: 0.0536 - val_mae: 0.1684 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0282 - mae: 0.1321 - val_loss: 0.0536 - val_mae: 0.1684 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0281 - mae: 0.1322 - val_loss: 0.0456 - val_mae: 0.1538 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0281 - mae: 0.1322 - val_loss: 0.0456 - val_mae: 0.1538 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0282 - mae: 0.1314 - val_loss: 0.0459 - val_mae: 0.1522 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0282 - mae: 0.1314 - val_loss: 0.0459 - val_mae: 0.1522 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0272 - mae: 0.1301 - val_loss: 0.0463 - val_mae: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0272 - mae: 0.1301 - val_loss: 0.0463 - val_mae: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0263 - mae: 0.1258 - val_loss: 0.0456 - val_mae: 0.1518 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0263 - mae: 0.1258 - val_loss: 0.0456 - val_mae: 0.1518 - learning_rate: 5.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0272 - mae: 0.1292 - val_loss: 0.0476 - val_mae: 0.1550 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0272 - mae: 0.1292 - val_loss: 0.0476 - val_mae: 0.1550 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0260 - mae: 0.1262 - val_loss: 0.0419 - val_mae: 0.1445 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0260 - mae: 0.1262 - val_loss: 0.0419 - val_mae: 0.1445 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0253 - mae: 0.1266 - val_loss: 0.0381 - val_mae: 0.1359 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0253 - mae: 0.1266 - val_loss: 0.0381 - val_mae: 0.1359 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0241 - mae: 0.1221 - val_loss: 0.0426 - val_mae: 0.1466 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0241 - mae: 0.1221 - val_loss: 0.0426 - val_mae: 0.1466 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0243 - mae: 0.1246 - val_loss: 0.0375 - val_mae: 0.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0243 - mae: 0.1246 - val_loss: 0.0375 - val_mae: 0.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0244 - mae: 0.1223 - val_loss: 0.0400 - val_mae: 0.1406 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.0244 - mae: 0.1223 - val_loss: 0.0400 - val_mae: 0.1406 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0230 - mae: 0.1213 - val_loss: 0.0371 - val_mae: 0.1340 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0230 - mae: 0.1213 - val_loss: 0.0371 - val_mae: 0.1340 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0220 - mae: 0.1180 - val_loss: 0.0400 - val_mae: 0.1399 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0220 - mae: 0.1180 - val_loss: 0.0400 - val_mae: 0.1399 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0229 - mae: 0.1196 - val_loss: 0.0378 - val_mae: 0.1374 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.0229 - mae: 0.1196 - val_loss: 0.0378 - val_mae: 0.1374 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0231 - mae: 0.1189 - val_loss: 0.0363 - val_mae: 0.1351 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0231 - mae: 0.1189 - val_loss: 0.0363 - val_mae: 0.1351 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0228 - mae: 0.1187 - val_loss: 0.0412 - val_mae: 0.1456 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0228 - mae: 0.1187 - val_loss: 0.0412 - val_mae: 0.1456 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0223 - mae: 0.1167 - val_loss: 0.0387 - val_mae: 0.1397 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0223 - mae: 0.1167 - val_loss: 0.0387 - val_mae: 0.1397 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0220 - mae: 0.1174 - val_loss: 0.0367 - val_mae: 0.1344 - learning_rate: 5.0000e-04\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0220 - mae: 0.1174 - val_loss: 0.0367 - val_mae: 0.1344 - learning_rate: 5.0000e-04\n",
      "Fold 4 MSE: 0.036301\n",
      "Fold 4 MSE: 0.036301\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\n",
      "Fold 5/5\n",
      "Training set shape: X=(1915, 60, 8), y=(1915, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - loss: 0.8213 - mae: 0.7090 - val_loss: 2.7773 - val_mae: 1.5557 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - loss: 0.8213 - mae: 0.7090 - val_loss: 2.7773 - val_mae: 1.5557 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4811 - mae: 0.5455 - val_loss: 1.9968 - val_mae: 1.2882 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.4811 - mae: 0.5455 - val_loss: 1.9968 - val_mae: 1.2882 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3778 - mae: 0.4815 - val_loss: 2.0703 - val_mae: 1.3067 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.3778 - mae: 0.4815 - val_loss: 2.0703 - val_mae: 1.3067 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.3184 - mae: 0.4444 - val_loss: 1.7486 - val_mae: 1.1941 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.3184 - mae: 0.4444 - val_loss: 1.7486 - val_mae: 1.1941 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2687 - mae: 0.4012 - val_loss: 1.9119 - val_mae: 1.2489 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.2687 - mae: 0.4012 - val_loss: 1.9119 - val_mae: 1.2489 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.2079 - mae: 0.3607 - val_loss: 1.5432 - val_mae: 1.1042 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.2079 - mae: 0.3607 - val_loss: 1.5432 - val_mae: 1.1042 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.1922 - mae: 0.3431 - val_loss: 1.1816 - val_mae: 0.9340 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.1922 - mae: 0.3431 - val_loss: 1.1816 - val_mae: 0.9340 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1571 - mae: 0.3115 - val_loss: 1.1039 - val_mae: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.1571 - mae: 0.3115 - val_loss: 1.1039 - val_mae: 0.9117 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1366 - mae: 0.2909 - val_loss: 1.0063 - val_mae: 0.8517 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1366 - mae: 0.2909 - val_loss: 1.0063 - val_mae: 0.8517 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1130 - mae: 0.2651 - val_loss: 1.1260 - val_mae: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.1130 - mae: 0.2651 - val_loss: 1.1260 - val_mae: 0.9068 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0978 - mae: 0.2464 - val_loss: 0.9979 - val_mae: 0.8430 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0978 - mae: 0.2464 - val_loss: 0.9979 - val_mae: 0.8430 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0902 - mae: 0.2356 - val_loss: 1.0003 - val_mae: 0.8471 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0902 - mae: 0.2356 - val_loss: 1.0003 - val_mae: 0.8471 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0802 - mae: 0.2241 - val_loss: 0.9384 - val_mae: 0.8071 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0802 - mae: 0.2241 - val_loss: 0.9384 - val_mae: 0.8071 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0675 - mae: 0.2049 - val_loss: 0.8875 - val_mae: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0675 - mae: 0.2049 - val_loss: 0.8875 - val_mae: 0.7845 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0643 - mae: 0.2006 - val_loss: 0.9136 - val_mae: 0.7971 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0643 - mae: 0.2006 - val_loss: 0.9136 - val_mae: 0.7971 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.0564 - mae: 0.1895 - val_loss: 0.8452 - val_mae: 0.7624 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.0564 - mae: 0.1895 - val_loss: 0.8452 - val_mae: 0.7624 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0536 - mae: 0.1827 - val_loss: 0.8415 - val_mae: 0.7630 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0536 - mae: 0.1827 - val_loss: 0.8415 - val_mae: 0.7630 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0494 - mae: 0.1777 - val_loss: 0.8963 - val_mae: 0.7924 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0494 - mae: 0.1777 - val_loss: 0.8963 - val_mae: 0.7924 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0469 - mae: 0.1717 - val_loss: 0.8686 - val_mae: 0.7813 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0469 - mae: 0.1717 - val_loss: 0.8686 - val_mae: 0.7813 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0444 - mae: 0.1687 - val_loss: 0.8777 - val_mae: 0.7835 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0444 - mae: 0.1687 - val_loss: 0.8777 - val_mae: 0.7835 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0434 - mae: 0.1667 - val_loss: 0.7554 - val_mae: 0.7122 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0434 - mae: 0.1667 - val_loss: 0.7554 - val_mae: 0.7122 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0402 - mae: 0.1606 - val_loss: 0.8199 - val_mae: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0402 - mae: 0.1606 - val_loss: 0.8199 - val_mae: 0.7537 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0368 - mae: 0.1523 - val_loss: 0.7843 - val_mae: 0.7329 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0368 - mae: 0.1523 - val_loss: 0.7843 - val_mae: 0.7329 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0368 - mae: 0.1533 - val_loss: 0.7121 - val_mae: 0.6874 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0368 - mae: 0.1533 - val_loss: 0.7121 - val_mae: 0.6874 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0366 - mae: 0.1527 - val_loss: 0.7617 - val_mae: 0.7185 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0366 - mae: 0.1527 - val_loss: 0.7617 - val_mae: 0.7185 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0356 - mae: 0.1498 - val_loss: 0.6732 - val_mae: 0.6675 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0356 - mae: 0.1498 - val_loss: 0.6732 - val_mae: 0.6675 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.0354 - mae: 0.1497 - val_loss: 0.6689 - val_mae: 0.6655 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.0354 - mae: 0.1497 - val_loss: 0.6689 - val_mae: 0.6655 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0330 - mae: 0.1447 - val_loss: 0.6722 - val_mae: 0.6687 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0330 - mae: 0.1447 - val_loss: 0.6722 - val_mae: 0.6687 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0334 - mae: 0.1467 - val_loss: 0.6530 - val_mae: 0.6564 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0334 - mae: 0.1467 - val_loss: 0.6530 - val_mae: 0.6564 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0328 - mae: 0.1451 - val_loss: 0.6470 - val_mae: 0.6555 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0328 - mae: 0.1451 - val_loss: 0.6470 - val_mae: 0.6555 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0317 - mae: 0.1417 - val_loss: 0.6183 - val_mae: 0.6345 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0317 - mae: 0.1417 - val_loss: 0.6183 - val_mae: 0.6345 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0316 - mae: 0.1426 - val_loss: 0.5704 - val_mae: 0.6032 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0316 - mae: 0.1426 - val_loss: 0.5704 - val_mae: 0.6032 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0327 - mae: 0.1440 - val_loss: 0.6015 - val_mae: 0.6220 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0327 - mae: 0.1440 - val_loss: 0.6015 - val_mae: 0.6220 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0315 - mae: 0.1404 - val_loss: 0.5872 - val_mae: 0.6143 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0315 - mae: 0.1404 - val_loss: 0.5872 - val_mae: 0.6143 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0323 - mae: 0.1441 - val_loss: 0.6358 - val_mae: 0.6467 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0323 - mae: 0.1441 - val_loss: 0.6358 - val_mae: 0.6467 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0312 - mae: 0.1416 - val_loss: 0.6150 - val_mae: 0.6278 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0312 - mae: 0.1416 - val_loss: 0.6150 - val_mae: 0.6278 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0311 - mae: 0.1416 - val_loss: 0.6088 - val_mae: 0.6243 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0311 - mae: 0.1416 - val_loss: 0.6088 - val_mae: 0.6243 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0306 - mae: 0.1387 - val_loss: 0.6026 - val_mae: 0.6206 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0306 - mae: 0.1387 - val_loss: 0.6026 - val_mae: 0.6206 - learning_rate: 5.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0298 - mae: 0.1370 - val_loss: 0.6108 - val_mae: 0.6253 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0298 - mae: 0.1370 - val_loss: 0.6108 - val_mae: 0.6253 - learning_rate: 5.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0303 - mae: 0.1403 - val_loss: 0.5742 - val_mae: 0.5979 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 0.0303 - mae: 0.1403 - val_loss: 0.5742 - val_mae: 0.5979 - learning_rate: 5.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0304 - mae: 0.1394 - val_loss: 0.5829 - val_mae: 0.6068 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0304 - mae: 0.1394 - val_loss: 0.5829 - val_mae: 0.6068 - learning_rate: 5.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0309 - mae: 0.1406 - val_loss: 0.5706 - val_mae: 0.5970 - learning_rate: 5.0000e-04\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 0.0309 - mae: 0.1406 - val_loss: 0.5706 - val_mae: 0.5970 - learning_rate: 5.0000e-04\n",
      "Fold 5 MSE: 0.570369\n",
      "Fold 5 MSE: 0.570369\n",
      "Error processing AMGN: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing AMZN...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Error processing AMGN: non-broadcastable output operand with shape (1975,1) doesn't match the broadcast shape (1975,8)\n",
      "\n",
      "Processing AMZN...\n",
      "Feature shape: (2370, 8)\n",
      "X shape: (2310, 60, 8), y shape: (2310, 1)\n",
      "\n",
      "Testing model initialization...\n",
      "Model architecture created successfully\n",
      "Test batch shape: (2, 60, 8)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Test prediction shape: (2, 1)\n",
      "Model test successful\n",
      "\n",
      "Fold 1/5\n",
      "Training set shape: X=(335, 60, 8), y=(335, 1)\n",
      "Validation set shape: X=(395, 60, 8), y=(395, 1)\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 3.5737 - mae: 1.4937"
     ]
    }
   ],
   "source": [
    "# Suppress TensorFlow deprecation warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "# Train models with cross-validation\n",
    "cv = create_time_series_cv()\n",
    "stock_predictions = {}\n",
    "stock_models = {}\n",
    "\n",
    "try:\n",
    "    for ticker in stock_features.keys():\n",
    "        print(f\"\\nProcessing {ticker}...\")\n",
    "        features = stock_features[ticker].values\n",
    "        print(f\"Feature shape: {features.shape}\")\n",
    "        \n",
    "        # Prepare sequences\n",
    "        try:\n",
    "            X, y, scaler = prepare_sequence_data(features)\n",
    "            print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "            \n",
    "            # Test model with small batch first\n",
    "            print(\"\\nTesting model initialization...\")\n",
    "            try:\n",
    "                # Create model once for testing\n",
    "                model = create_improved_lstm_model(input_shape=(X.shape[1], X.shape[2]))\n",
    "                print(\"Model architecture created successfully\")\n",
    "                \n",
    "                # Test forward pass with small batch\n",
    "                test_batch = X[:2]\n",
    "                print(f\"Test batch shape: {test_batch.shape}\")\n",
    "                test_pred = model.predict(test_batch, verbose=0)\n",
    "                print(f\"Test prediction shape: {test_pred.shape}\")\n",
    "                print(\"Model test successful\")\n",
    "                \n",
    "                # Clean up test model to free memory\n",
    "                del model\n",
    "                tf.keras.backend.clear_session()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Model test failed: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Initialize lists for cross-validation results\n",
    "            val_predictions = []\n",
    "            val_indices = []\n",
    "            \n",
    "            # Cross-validation training\n",
    "            for fold, (train_idx, val_idx) in enumerate(cv.split(X)):\n",
    "                print(f\"\\nFold {fold + 1}/5\")\n",
    "                try:\n",
    "                    X_train, X_val = X[train_idx], X[val_idx]\n",
    "                    y_train, y_val = y[train_idx], y[val_idx]\n",
    "                    \n",
    "                    print(f\"Training set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "                    print(f\"Validation set shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "                    \n",
    "                    # Create fresh model for each fold\n",
    "                    model = create_improved_lstm_model(input_shape=(X.shape[1], X.shape[2]))\n",
    "                    \n",
    "                    # Callbacks\n",
    "                    callbacks = [\n",
    "                        tf.keras.callbacks.EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            patience=10,\n",
    "                            restore_best_weights=True\n",
    "                        ),\n",
    "                        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                            monitor='val_loss',\n",
    "                            factor=0.5,\n",
    "                            patience=5,\n",
    "                            min_lr=0.0001\n",
    "                        )\n",
    "                    ]\n",
    "                    \n",
    "                    # Train the model\n",
    "                    history = model.fit(\n",
    "                        X_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=1\n",
    "                    )\n",
    "                    \n",
    "                    # Store predictions\n",
    "                    fold_predictions = model.predict(X_val, verbose=0)\n",
    "                    val_predictions.extend(fold_predictions.flatten())\n",
    "                    val_indices.extend(val_idx)\n",
    "                    \n",
    "                    # Print fold metrics\n",
    "                    fold_mse = model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "                    print(f\"Fold {fold + 1} MSE: {fold_mse:.6f}\")\n",
    "                    \n",
    "                    # Clean up fold model to free memory\n",
    "                    del model\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in fold {fold + 1}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if len(val_predictions) > 0:\n",
    "                # Store predictions\n",
    "                stock_predictions[ticker] = pd.Series(\n",
    "                    scaler.inverse_transform(np.array(val_predictions).reshape(-1, 1)).flatten(),\n",
    "                    index=merged_df.index[60:][val_indices]\n",
    "                )\n",
    "                \n",
    "                # Print final metrics\n",
    "                final_mse = np.mean((stock_predictions[ticker] - features[60:, 0][val_indices]) ** 2)\n",
    "                print(f\"\\n{ticker} - Final MSE: {final_mse:.6f}\")\n",
    "            else:\n",
    "                print(f\"\\nNo valid predictions for {ticker}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in main training loop: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Successfully processed stocks: {len(stock_predictions)}/{len(stock_features)}\")\n",
    "for ticker in stock_predictions.keys():\n",
    "    print(f\"{ticker}: {len(stock_predictions[ticker])} predictions\")\n",
    "\n",
    "# Save predictions if we have any\n",
    "if len(stock_predictions) > 0:\n",
    "    predictions_df = pd.DataFrame(stock_predictions)\n",
    "    predictions_df.to_csv(\"data/processed/lstm_predictions.csv\")\n",
    "    print(\"\\nPredictions saved to lstm_predictions.csv\")\n",
    "else:\n",
    "    print(\"\\nNo predictions to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6b17d",
   "metadata": {},
   "source": [
    "## 3. Portfolio Optimization Setup\n",
    "\n",
    "Prepare the predicted returns and risk metrics for portfolio optimization with ESG constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e00528",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = predictions_df.pct_change().dropna()\n",
    "exp_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "# Add ESG constraints\n",
    "esg_threshold = 0.6  \n",
    "min_esg_weight = 0.4  \n",
    "\n",
    "high_esg_stocks = esg_scores[esg_scores['esg_score'] >= esg_threshold].index\n",
    "\n",
    "def portfolio_stats(weights):\n",
    "    portfolio_return = np.sum(exp_returns * weights)\n",
    "    portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = portfolio_return / portfolio_risk\n",
    "    \n",
    "    portfolio_esg = np.sum(esg_scores['esg_score'] * weights)\n",
    "    return portfolio_return, portfolio_risk, sharpe_ratio, portfolio_esg\n",
    "\n",
    "def optimize_portfolio(target_return=None):\n",
    "    n_assets = len(exp_returns)\n",
    "    \n",
    "    weights = np.array([1/n_assets] * n_assets)\n",
    "    \n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # Sum of weights = 1\n",
    "        {'type': 'ineq', 'fun': lambda x: np.sum(x[esg_scores.index.isin(high_esg_stocks)]) - min_esg_weight}  # ESG constraint\n",
    "    ]\n",
    "    \n",
    "    if target_return is not None:\n",
    "        constraints.append({\n",
    "            'type': 'eq',\n",
    "            'fun': lambda x: np.sum(exp_returns * x) - target_return\n",
    "        })\n",
    "    \n",
    "    bounds = tuple((0, 0.2) for asset in range(n_assets))\n",
    "    \n",
    "    def objective(weights):\n",
    "        return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    \n",
    "    result = minimize(objective, weights, method='SLSQP',\n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x if result.success else None\n",
    "\n",
    "target_returns = np.linspace(exp_returns.min(), exp_returns.max(), 50)\n",
    "efficient_portfolios = []\n",
    "\n",
    "for target in target_returns:\n",
    "    weights = optimize_portfolio(target)\n",
    "    if weights is not None:\n",
    "        stats = portfolio_stats(weights)\n",
    "        efficient_portfolios.append({\n",
    "            'Return': stats[0],\n",
    "            'Risk': stats[1],\n",
    "            'Sharpe': stats[2],\n",
    "            'ESG Score': stats[3],\n",
    "            'Weights': weights\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d17e62",
   "metadata": {},
   "source": [
    "## 4. Portfolio Analysis and Visualization\n",
    "\n",
    "Analyze the optimized portfolios and create visualizations of the efficient frontier and portfolio weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert efficient portfolios to DataFrame\n",
    "ef_df = pd.DataFrame([{\n",
    "    'Return': p['Return'],\n",
    "    'Risk': p['Risk'],\n",
    "    'Sharpe': p['Sharpe'],\n",
    "    'ESG Score': p['ESG Score']\n",
    "} for p in efficient_portfolios])\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(ef_df['Risk'], ef_df['Return'], c=ef_df['ESG Score'], \n",
    "           cmap='viridis', s=50)\n",
    "plt.colorbar(label='ESG Score')\n",
    "plt.xlabel('Portfolio Risk (Volatility)')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Efficient Frontier with ESG Scores')\n",
    "plt.show()\n",
    "\n",
    "# Find optimal portfolio (highest Sharpe ratio)\n",
    "optimal_idx = ef_df['Sharpe'].idxmax()\n",
    "optimal_portfolio = efficient_portfolios[optimal_idx]\n",
    "\n",
    "# Plot optimal portfolio weights\n",
    "optimal_weights = pd.Series(\n",
    "    optimal_portfolio['Weights'], \n",
    "    index=exp_returns.index\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "optimal_weights.plot(kind='bar')\n",
    "plt.title('Optimal Portfolio Weights')\n",
    "plt.xlabel('Stocks')\n",
    "plt.ylabel('Weight')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print portfolio statistics\n",
    "print(\"\\nOptimal Portfolio Statistics:\")\n",
    "print(f\"Expected Return: {optimal_portfolio['Return']:.4f}\")\n",
    "print(f\"Risk: {optimal_portfolio['Risk']:.4f}\")\n",
    "print(f\"Sharpe Ratio: {optimal_portfolio['Sharpe']:.4f}\")\n",
    "print(f\"ESG Score: {optimal_portfolio['ESG Score']:.4f}\")\n",
    "\n",
    "# Calculate maximum drawdown\n",
    "def calculate_max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    rolling_max = cumulative.expanding().max()\n",
    "    drawdowns = cumulative / rolling_max - 1\n",
    "    return drawdowns.min()\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns = returns.dot(optimal_portfolio['Weights'])\n",
    "max_drawdown = calculate_max_drawdown(portfolio_returns)\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.4f}\")\n",
    "\n",
    "# Save optimal portfolio\n",
    "optimal_portfolio_df = pd.DataFrame({\n",
    "    'Weight': optimal_weights,\n",
    "    'ESG Score': esg_scores['esg_score']\n",
    "})\n",
    "optimal_portfolio_df.to_csv('data/processed/optimal_portfolio.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
